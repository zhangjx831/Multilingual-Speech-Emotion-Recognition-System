{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f52390",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcff203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "regex = re.compile(r'\\[.+\\]\\n', re.IGNORECASE)\n",
    "file_paths, file_names, sessions, emotions = [], [], [], []\n",
    "emotion_map = {'neu': 'neutral', 'ang': 'angry', 'hap': 'happy', 'exc': 'happy', 'sad': 'sad'}\n",
    "\n",
    "for session in range(1, 6):\n",
    "    emo_evaluation_dir = f'/home/jz3313/IEMOCAP_full_release/Session{session}/dialog/EmoEvaluation/'\n",
    "    file_dir = f'/home/jz3313/IEMOCAP_full_release/Session{session}/sentences/wav/'\n",
    "    evaluation_files = [l for l in os.listdir(emo_evaluation_dir) if 'Ses' in l]\n",
    "    for file in evaluation_files:\n",
    "        with open(emo_evaluation_dir + file) as f:\n",
    "            content = f.read()\n",
    "        lines = re.findall(regex, content)\n",
    "        for line in lines[1:]:  # the first line is a header\n",
    "            start_end_time, wav_file_name, emotion, val_act_dom = line.strip().split('\\t')\n",
    "            dir_name = '_'.join(wav_file_name.split('_')[:-1])\n",
    "            if emotion in emotion_map:\n",
    "                file_paths.append(file_dir+dir_name+'/'+wav_file_name+'.wav')\n",
    "                file_names.append(wav_file_name)\n",
    "                sessions.append(session)\n",
    "                emotions.append(emotion_map[emotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cd075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.DataFrame({'path':file_paths, 'name': file_names, 'session': sessions, 'emotion': emotions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277cf819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>session</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F000</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F001</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F002</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F003</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F004</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path                 name  \\\n",
       "0  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F000   \n",
       "1  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F001   \n",
       "2  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F002   \n",
       "3  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F003   \n",
       "4  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F004   \n",
       "\n",
       "   session  emotion  \n",
       "0        1      sad  \n",
       "1        1      sad  \n",
       "2        1      sad  \n",
       "3        1  neutral  \n",
       "4        1      sad  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42fa07c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "0.12.1+cu113\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67c39ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchaudio.models.wav2vec2.model.Wav2Vec2Model'>\n"
     ]
    }
   ],
   "source": [
    "bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
    "extractor = bundle.get_model()\n",
    "print(extractor.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for _, row in tqdm(file.iterrows()):\n",
    "    path, name, session, emotion = row[0], row[1], row[2], row[3]\n",
    "    wave, sr = torchaudio.load(path)\n",
    "    if sr != bundle.sample_rate:\n",
    "        wave = torchaudio.functional.resample(wave, sr, bundle.sample_rate)\n",
    "    with torch.inference_mode():\n",
    "        feature, _ = extractor.extract_features(wave)\n",
    "    feature = [f[0] for f in feature]\n",
    "    feature = torch.stack(feature)\n",
    "    save_path = f'../data/wav2vecbase/Session{session}/{name}.pt'\n",
    "    torch.save(feature, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7be560",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d955c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file['newpath'] = file.apply(lambda x: f'../data/wav2vecbase/Session{x[2]}/{x[1]}.pt', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd4ffa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>session</th>\n",
       "      <th>emotion</th>\n",
       "      <th>newpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F000</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>../data/wav2vecbase/Session1/Ses01F_impro02_F0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F001</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>../data/wav2vecbase/Session1/Ses01F_impro02_F0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F002</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>../data/wav2vecbase/Session1/Ses01F_impro02_F0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F003</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>../data/wav2vecbase/Session1/Ses01F_impro02_F0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jz3313/IEMOCAP_full_release/Session1/sen...</td>\n",
       "      <td>Ses01F_impro02_F004</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>../data/wav2vecbase/Session1/Ses01F_impro02_F0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path                 name  \\\n",
       "0  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F000   \n",
       "1  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F001   \n",
       "2  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F002   \n",
       "3  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F003   \n",
       "4  /home/jz3313/IEMOCAP_full_release/Session1/sen...  Ses01F_impro02_F004   \n",
       "\n",
       "   session  emotion                                            newpath  \n",
       "0        1      sad  ../data/wav2vecbase/Session1/Ses01F_impro02_F0...  \n",
       "1        1      sad  ../data/wav2vecbase/Session1/Ses01F_impro02_F0...  \n",
       "2        1      sad  ../data/wav2vecbase/Session1/Ses01F_impro02_F0...  \n",
       "3        1  neutral  ../data/wav2vecbase/Session1/Ses01F_impro02_F0...  \n",
       "4        1      sad  ../data/wav2vecbase/Session1/Ses01F_impro02_F0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb4cd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = 1\n",
    "train = file[file['session'] != holdout]\n",
    "test = file[file['session'] == holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a75bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, labels, label_transform):\n",
    "        super(MyDataSet).__init__()\n",
    "        self.datas = datas\n",
    "        self.labels = labels\n",
    "        self.label_transform = label_transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        audio = self.datas[idx]\n",
    "        label = self.label_transform[self.labels[idx]]\n",
    "        length = audio.size(1)\n",
    "        return audio, length, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141ec40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(data):\n",
    "    audios, lengths, labels = zip(*data)\n",
    "    max_len = max(lengths)\n",
    "    n_ftrs = audios[0].size(2)\n",
    "    n_dims = audios[0].size(0)\n",
    "    features = torch.zeros((len(audios), n_dims, max_len, n_ftrs))\n",
    "    labels = torch.tensor(labels)\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        j, k = audios[i].size(1), audios[i].size(2)\n",
    "        features[i] = torch.cat([audios[i], torch.zeros((n_dims, max_len - j, k))], dim=1)\n",
    "\n",
    "    return features, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0738ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0, 'happy': 1, 'neutral': 2, 'sad': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['angry', 'happy', 'neutral', 'sad']\n",
    "cate_dic = {}\n",
    "for i, cate in enumerate(categories):\n",
    "    cate_dic[cate] = i\n",
    "cate_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4848c",
   "metadata": {},
   "source": [
    "## Train with 3CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef1a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ICASSP3CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, dims = 12, embed_size=128, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=7):\n",
    "        super().__init__()\n",
    "        self.n_layers = num_lstm_layers \n",
    "        self.hidden = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.aggr = nn.Conv1d(in_channels=dims, out_channels=1, kernel_size=1)\n",
    "        \n",
    "        self.embed = nn.Linear(in_features = vocab_size, out_features = embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(3 * embed_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = 3 * embed_size, \n",
    "                            hidden_size = hidden_size, \n",
    "                            num_layers = num_lstm_layers, \n",
    "                            bidirectional = bidirectional)\n",
    "\n",
    "        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n",
    "                                out_features = label_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "        n, d, b, t = x.size(0), x.size(1), x.size(2), x.size(3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        input = self.aggr(x)\n",
    "        input = torch.reshape(input, (n, b, t))\n",
    "        input = self.embed(input)\n",
    "\n",
    "        batch_size = input.size(0)\n",
    "        input = input.transpose(1,2)    # (B,T,H) -> (B,H,T)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n",
    "            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n",
    "        else:\n",
    "            h_n = hn[-1]\n",
    "\n",
    "        logits = self.linear(h_n)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7d392",
   "metadata": {},
   "source": [
    "### Model Traning on each layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d051d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4446it [05:48, 12.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "traindata = []\n",
    "for _, row in tqdm(train.iterrows()):\n",
    "    traindata.append(torch.load(row[4]))\n",
    "\n",
    "train_dataset = MyDataSet(traindata, train['emotion'].tolist(), cate_dic)\n",
    "trainloader_args = dict(batch_size=32, shuffle=True)\n",
    "train_dataloader = DataLoader(train_dataset, **trainloader_args, \n",
    "                              collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6942285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "\n",
    "model = ICASSP3CNN(768, bidirectional = True, label_size=4)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75762bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▌                                                                                                                                                                 | 1/30 [01:53<54:49, 113.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, train accu:0.5112, train loss:1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|███████████▏                                                                                                                                                           | 2/30 [03:41<51:35, 110.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2, train accu:0.6194, train loss:0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████████████▋                                                                                                                                                      | 3/30 [05:30<49:18, 109.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3, train accu:0.6658, train loss:0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████████████████▎                                                                                                                                                | 4/30 [07:17<47:07, 108.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4, train accu:0.7054, train loss:0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████████████████████████▊                                                                                                                                           | 5/30 [09:06<45:17, 108.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5, train accu:0.7341, train loss:0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████████████████████████████████▍                                                                                                                                     | 6/30 [10:56<43:40, 109.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6, train accu:0.7587, train loss:0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████████████████████████▉                                                                                                                                | 7/30 [12:46<41:58, 109.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7, train accu:0.7807, train loss:0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████████████████████████████▌                                                                                                                          | 8/30 [14:34<39:53, 108.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8, train accu:0.8099, train loss:0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████████████████████████████████                                                                                                                     | 9/30 [16:22<38:00, 108.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9, train accu:0.8401, train loss:0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████████████████████████████████▎                                                                                                              | 10/30 [18:10<36:11, 108.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, train accu:0.8707, train loss:0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|████████████████████████████████████████████████████████████▊                                                                                                         | 11/30 [20:00<34:30, 109.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11, train accu:0.8941, train loss:0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████████████████████████████████████████▍                                                                                                   | 12/30 [21:47<32:31, 108.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12, train accu:0.9008, train loss:0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████████████████████████████████████████▉                                                                                              | 13/30 [23:36<30:45, 108.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13, train accu:0.9283, train loss:0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████████████████████████████████████████████▍                                                                                        | 14/30 [25:27<29:05, 109.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14, train accu:0.9453, train loss:0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████████████████████████████████                                                                                   | 15/30 [27:15<27:12, 108.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15, train accu:0.9555, train loss:0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 16/30 [29:01<25:11, 107.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16, train accu:0.9681, train loss:0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 17/30 [30:51<23:34, 108.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17, train accu:0.9651, train loss:0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 18/30 [32:42<21:51, 109.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18, train accu:0.9705, train loss:0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 19/30 [34:31<20:02, 109.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19, train accu:0.9741, train loss:0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 20/30 [36:19<18:08, 108.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20, train accu:0.9782, train loss:0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 21/30 [38:08<16:19, 108.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21, train accu:0.9730, train loss:0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 22/30 [39:56<14:29, 108.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22, train accu:0.9685, train loss:0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 23/30 [41:43<12:37, 108.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23, train accu:0.9874, train loss:0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 24/30 [43:33<10:52, 108.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24, train accu:0.9840, train loss:0.04\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    model.train()\n",
    "    for batch, (x, length, y) in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x, length)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.cpu().item()\n",
    "\n",
    "        #model outputs\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "        batch_cnt += 1\n",
    "    \n",
    "    train_loss = train_loss/batch_cnt\n",
    "    train_accuracy = acc_cnt/(acc_cnt+err_cnt)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    print(f\"epoch:{epoch+1}, train accu:{train_accuracy:.4f},\", f\"train loss:{train_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42092bf7",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "testdata = []\n",
    "for _, row in tqdm(test.iterrows()):\n",
    "    testdata.append(torch.load(row[4]))\n",
    "    \n",
    "test_dataset = MyDataSet(testdata, test['emotion'].tolist(), cate_dic)\n",
    "testloader_args = dict(batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, **testloader_args, \n",
    "                             collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "acc_cnt = 0\n",
    "err_cnt = 0\n",
    "batch_cnt = 0\n",
    "model.eval()\n",
    "\n",
    "for x, lengths, y in test_dataloader:\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logits = model(x, lengths)\n",
    "    loss = criterion(logits, y)\n",
    "    test_loss += loss.cpu().item()\n",
    "\n",
    "    out_val, out_indices = torch.max(logits, dim=1)\n",
    "    tar_indices = y\n",
    "\n",
    "    for i in range(len(out_indices)):\n",
    "        if out_indices[i] == tar_indices[i]:\n",
    "            acc_cnt += 1\n",
    "        else:\n",
    "            err_cnt += 1\n",
    "    batch_cnt += 1\n",
    "\n",
    "test_loss = test_loss/batch_cnt\n",
    "test_accuracy = acc_cnt/(acc_cnt+err_cnt)\n",
    "print(f'test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'../models/wav2vecbase/holdout{holdout}.pth'\n",
    "\n",
    "torch.save({'epoch':epochs,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict()},\n",
    "            model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
