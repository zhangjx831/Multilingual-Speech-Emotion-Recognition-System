{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f52390",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072f4dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.12.1+cu113\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "bundle = torchaudio.pipelines.WAV2VEC2_LARGE\n",
    "model_extr = bundle.get_model().to(device)\n",
    "\n",
    "main_path = '/home/wawa_/'\n",
    "\n",
    "emotion_map = {'Neutre': 'neutral', 'Colère': 'angry', 'Joie': 'happy', 'Tristesse': 'sad', 'Peur': 'fear',\n",
    "              'Dégoût': 'disgust', 'Surprise': 'surprise'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81a803d0",
   "metadata": {},
   "source": [
    "# Generate features (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2bf642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# data_path = '/home/wawa_/CaFE/High resolution (192kHz)/'\n",
    "# folders = ['Joie', 'Peur', 'Tristesse', 'Colère', 'Dégoût', 'Neutre', 'Surprise']\n",
    "# audios = []\n",
    "# labels = []\n",
    "# file_paths = []\n",
    "# for folder in folders:\n",
    "#   if folder!='Neutre':\n",
    "#     subfolders = ['Fort/', 'Faible/']\n",
    "#   else:\n",
    "#     subfolders = ['']\n",
    "#   for subfolder in subfolders:\n",
    "#     dir_path = data_path + folder + '/' + subfolder\n",
    "#     for file in os.listdir(dir_path):\n",
    "#         if 'aiff' not in file:\n",
    "#             continue\n",
    "#         name = file.split('.')[0]\n",
    "#         file_path = dir_path + file\n",
    "#         labels.append(folder)\n",
    "#         wave, sr = torchaudio.load(file_path)\n",
    "#         wave = wave.to(device)\n",
    "#         if sr != bundle.sample_rate:\n",
    "#             wave = torchaudio.functional.resample(wave, sr, bundle.sample_rate)\n",
    "  \n",
    "#         with torch.inference_mode():\n",
    "#             feature, _ = model_extr.extract_features(wave)\n",
    "#         feature = [f[0] for f in feature]\n",
    "#         feature = torch.stack(feature)\n",
    "#         save_path_folder = f'/home/wawa_/data/wav2vecbase/{folder}/{subfolder}'\n",
    "#         os.makedirs(save_path_folder, exist_ok = True) \n",
    "#         save_path = f'/home/wawa_/data/wav2vecbase/{folder}/{subfolder}{name}.pt'\n",
    "#         torch.save(feature, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f81d6",
   "metadata": {},
   "source": [
    "# Generate Sessions (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c93e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = main_path + 'CaFE/High resolution (192kHz)/'\n",
    "# features_path = main_path + 'data/wav2vecbase/'\n",
    "\n",
    "# feat_extension = '.pt'\n",
    "\n",
    "# keep_strong_only = False\n",
    "\n",
    "# folders = ['Joie', 'Peur', 'Tristesse', 'Colère', 'Dégoût', 'Neutre', 'Surprise']\n",
    "# labels = []\n",
    "\n",
    "# file_paths = []\n",
    "# new_file_paths = []\n",
    "# strengths = []\n",
    "\n",
    "# for folder in folders:\n",
    "#   if folder!='Neutre':\n",
    "#     subfolders = ['Fort/', 'Faible/']\n",
    "#   else:\n",
    "#     subfolders = ['']\n",
    "#   for subfolder in subfolders:\n",
    "#     dir_path = data_path + folder + '/' + subfolder\n",
    "#     dir_path_features = features_path + folder + '/' + subfolder\n",
    "#     for file in os.listdir(dir_path):\n",
    "#         if 'aiff' not in file:\n",
    "#             continue\n",
    "#         if keep_strong_only and subfolder == 'Faible/':\n",
    "#             continue              \n",
    "#         file_path = dir_path + file\n",
    "#         new_file_path = dir_path_features + file.split('.')[0] + feat_extension\n",
    "        \n",
    "#         if subfolder == '':\n",
    "#           strengths.append('Fort')\n",
    "#         else:\n",
    "#           strengths.append(subfolder.split('/')[0])\n",
    "\n",
    "#         labels.append(emotion_map[folder])\n",
    "#         file_paths.append(file_path)\n",
    "#         new_file_paths.append(new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd19ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "\n",
    "# def shuffle_lists(list1, list2, list3, list4):\n",
    "#     combined = list(zip(list1, list2, list3, list4))\n",
    "#     random.shuffle(combined)\n",
    "#     return zip(*combined)\n",
    "\n",
    "# file_paths, new_file_paths, labels, strengths = shuffle_lists(file_paths, new_file_paths, labels, strengths)\n",
    "\n",
    "# sessions = []\n",
    "# file_names = []\n",
    "\n",
    "# equal_parts = (len(file_paths)-1)//5 # for equally split the file_paths into 5 parts\n",
    "# count = 0\n",
    "# for i in tqdm(range(len(file_paths))):\n",
    "#     file_path = file_paths[i]\n",
    "#     if \"aiff\" not in file_path:\n",
    "#         continue\n",
    "#     file_name = file_path.split('/')[-1]\n",
    "#     file_names.append(file_name)\n",
    "#     # assign session to it\n",
    "#     part = (count//equal_parts)%6 + 1\n",
    "#     if part == 6:\n",
    "#         part = 5\n",
    "#     sessions.append(part)\n",
    "#     count += 1\n",
    "\n",
    "# file = pd.DataFrame({'path':file_paths, 'feat_path': new_file_paths, 'name': file_names, 'emotion': labels, 'strength': strengths, 'session': sessions})\n",
    "# dataframe_path = main_path + 'session_entries.csv'\n",
    "# file.to_csv(dataframe_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7be560",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ef2595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>feat_path</th>\n",
       "      <th>name</th>\n",
       "      <th>emotion</th>\n",
       "      <th>strength</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/wawa_/CaFE/High resolution (192kHz)/Dégo...</td>\n",
       "      <td>/home/wawa_/data/wav2vecbase/Dégoût/Fort/03-D-...</td>\n",
       "      <td>03-D-2-2.aiff</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Fort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/wawa_/CaFE/High resolution (192kHz)/Neut...</td>\n",
       "      <td>/home/wawa_/data/wav2vecbase/Neutre/01-N-3.pt</td>\n",
       "      <td>01-N-3.aiff</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Fort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/wawa_/CaFE/High resolution (192kHz)/Tris...</td>\n",
       "      <td>/home/wawa_/data/wav2vecbase/Tristesse/Fort/02...</td>\n",
       "      <td>02-T-2-6.aiff</td>\n",
       "      <td>sad</td>\n",
       "      <td>Fort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/wawa_/CaFE/High resolution (192kHz)/Surp...</td>\n",
       "      <td>/home/wawa_/data/wav2vecbase/Surprise/Fort/08-...</td>\n",
       "      <td>08-S-2-6.aiff</td>\n",
       "      <td>surprise</td>\n",
       "      <td>Fort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/wawa_/CaFE/High resolution (192kHz)/Tris...</td>\n",
       "      <td>/home/wawa_/data/wav2vecbase/Tristesse/Fort/09...</td>\n",
       "      <td>09-T-2-5.aiff</td>\n",
       "      <td>sad</td>\n",
       "      <td>Fort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  /home/wawa_/CaFE/High resolution (192kHz)/Dégo...   \n",
       "1  /home/wawa_/CaFE/High resolution (192kHz)/Neut...   \n",
       "2  /home/wawa_/CaFE/High resolution (192kHz)/Tris...   \n",
       "4  /home/wawa_/CaFE/High resolution (192kHz)/Surp...   \n",
       "5  /home/wawa_/CaFE/High resolution (192kHz)/Tris...   \n",
       "\n",
       "                                           feat_path           name   emotion  \\\n",
       "0  /home/wawa_/data/wav2vecbase/Dégoût/Fort/03-D-...  03-D-2-2.aiff   disgust   \n",
       "1      /home/wawa_/data/wav2vecbase/Neutre/01-N-3.pt    01-N-3.aiff   neutral   \n",
       "2  /home/wawa_/data/wav2vecbase/Tristesse/Fort/02...  02-T-2-6.aiff       sad   \n",
       "4  /home/wawa_/data/wav2vecbase/Surprise/Fort/08-...  08-S-2-6.aiff  surprise   \n",
       "5  /home/wawa_/data/wav2vecbase/Tristesse/Fort/09...  09-T-2-5.aiff       sad   \n",
       "\n",
       "  strength  session  \n",
       "0     Fort        1  \n",
       "1     Fort        1  \n",
       "2     Fort        1  \n",
       "4     Fort        1  \n",
       "5     Fort        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the entries with assigned session\n",
    "dataframe_path = main_path + 'session_entries.csv'\n",
    "file = pd.read_csv(dataframe_path)[['path', 'feat_path', 'name', 'emotion', 'strength', 'session']]\n",
    "file = file[file['strength'] == 'Fort']\n",
    "\n",
    "\n",
    "# #### If on low_res data:\n",
    "# def fix_path(path):\n",
    "#     path2 = path.split('/')\n",
    "#     if path2[-1][3]=='N':\n",
    "#         path2[-1] = path2[-1][:5] + '1-' + path2[-1][5:]\n",
    "#     return '/'.join(path2)\n",
    "\n",
    "# def fix_name(name):\n",
    "#     if name[3]=='N':\n",
    "#         return name[:5] + '1-' + name[5:]\n",
    "#     else:\n",
    "#         return name\n",
    "\n",
    "# file['path'] = file['path'].map(fix_path)\n",
    "# file['feat_path'] = file['feat_path'].map(fix_path)\n",
    "# file['name'] = file['name'].map(fix_name)\n",
    "\n",
    "file.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07289a31",
   "metadata": {},
   "source": [
    "# Create Sessions and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4cd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = 1\n",
    "train = file[file['session'] != holdout]\n",
    "test = file[file['session'] == holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f62bde2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file[file['session']== holdout]['emotion'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a75bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, labels, label_transform):\n",
    "        super(MyDataSet).__init__()\n",
    "        self.datas = datas\n",
    "        self.labels = labels\n",
    "        self.label_transform = label_transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        audio = self.datas[idx]\n",
    "        label = self.label_transform[self.labels[idx]]\n",
    "        length = audio.size(1)\n",
    "        return audio, length, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141ec40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(data):\n",
    "    audios, lengths, labels = zip(*data)\n",
    "    max_len = max(lengths)\n",
    "    n_ftrs = audios[0].size(2)\n",
    "    n_dims = audios[0].size(0)\n",
    "    features = torch.zeros((len(audios), n_dims, max_len, n_ftrs))\n",
    "    labels = torch.tensor(labels).to(device)\n",
    "    lengths = torch.tensor(lengths).to(device)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        j, k = audios[i].size(1), audios[i].size(2)\n",
    "        features[i] = torch.cat([audios[i].to(device), torch.zeros((n_dims, max_len - j, k)).to(device)], dim=1).to(device)\n",
    "\n",
    "    return features, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0738ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0,\n",
       " 'angry': 1,\n",
       " 'happy': 2,\n",
       " 'sad': 3,\n",
       " 'fear': 4,\n",
       " 'disgust': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['neutral', 'angry', 'happy', 'sad', 'fear', 'disgust', 'surprise']\n",
    "cate_dic = {}\n",
    "for i, cate in enumerate(categories):\n",
    "    cate_dic[cate] = i\n",
    "cate_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4848c",
   "metadata": {},
   "source": [
    "## Train with 3CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ef1a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ICASSP3CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, dims = 12, embed_size=128, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=7):\n",
    "        super().__init__()\n",
    "        self.n_layers = num_lstm_layers \n",
    "        self.hidden = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.aggr = nn.Conv1d(in_channels=dims, out_channels=1, kernel_size=1)\n",
    "        \n",
    "        self.embed = nn.Linear(in_features = vocab_size, out_features = embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(3 * embed_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = 3 * embed_size, \n",
    "                            hidden_size = hidden_size, \n",
    "                            num_layers = num_lstm_layers, \n",
    "                            bidirectional = bidirectional)\n",
    "\n",
    "        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n",
    "                                out_features = label_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "        n, d, b, t = x.size(0), x.size(1), x.size(2), x.size(3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        input = self.aggr(x)\n",
    "        input = torch.reshape(input, (n, b, t))\n",
    "        input = self.embed(input)\n",
    "\n",
    "        batch_size = input.size(0)\n",
    "        input = input.transpose(1,2)    # (B,T,H) -> (B,H,T)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n",
    "            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n",
    "        else:\n",
    "            h_n = hn[-1]\n",
    "\n",
    "        logits = self.linear(h_n)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7d392",
   "metadata": {},
   "source": [
    "### Model Traning on each layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01d051d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:44,  2.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "traindata = []\n",
    "for _, row in tqdm(train.iterrows()):\n",
    "    traindata.append(torch.load(row['feat_path']).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b10d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataSet(traindata, train['emotion'].tolist(), cate_dic)\n",
    "trainloader_args = dict(batch_size=16, shuffle=True)\n",
    "train_dataloader = DataLoader(train_dataset, **trainloader_args, \n",
    "                              collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6942285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "\n",
    "model = ICASSP3CNN(1024, dims = 24)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75762bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:12<09:53, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, train accu:0.3375, train loss:1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:22<08:42, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2, train accu:0.5750, train loss:1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:32<08:16, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3, train accu:0.7025, train loss:0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:43<08:20, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4, train accu:0.7600, train loss:0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:53<07:54, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5, train accu:0.7850, train loss:0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [01:03<07:35, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6, train accu:0.8250, train loss:0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [01:13<07:22, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7, train accu:0.8975, train loss:0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [01:23<07:06, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8, train accu:0.9025, train loss:0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [01:34<06:59, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9, train accu:0.9250, train loss:0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [01:44<06:52, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, train accu:0.9500, train loss:0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [01:54<06:34, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11, train accu:0.9425, train loss:0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [02:04<06:22, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12, train accu:0.9425, train loss:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [02:14<06:10, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13, train accu:0.9250, train loss:0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [02:24<06:00, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14, train accu:0.9675, train loss:0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [02:34<05:53, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15, train accu:0.9675, train loss:0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [02:45<05:49, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16, train accu:0.9450, train loss:0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [02:54<05:34, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17, train accu:0.9775, train loss:0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [03:04<05:23, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18, train accu:0.9750, train loss:0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [03:14<05:08,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19, train accu:0.9800, train loss:0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [03:24<04:58,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20, train accu:0.9875, train loss:0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [03:34<04:53, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21, train accu:0.9900, train loss:0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [03:45<04:48, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22, train accu:0.9950, train loss:0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [03:55<04:34, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23, train accu:0.9975, train loss:0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [04:05<04:21, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24, train accu:0.9950, train loss:0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [04:15<04:10, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25, train accu:0.9825, train loss:0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [04:24<03:58,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26, train accu:0.9650, train loss:0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [04:35<03:54, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27, train accu:0.9900, train loss:0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [04:45<03:42, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28, train accu:0.9925, train loss:0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [04:55<03:30, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29, train accu:0.9900, train loss:0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [05:05<03:18,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30, train accu:0.9900, train loss:0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [05:14<03:07,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31, train accu:0.9825, train loss:0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [05:24<02:55,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32, train accu:0.9775, train loss:0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [05:34<02:47,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33, train accu:0.9050, train loss:0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [05:45<02:41, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34, train accu:0.9525, train loss:0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [05:54<02:29,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35, train accu:0.9700, train loss:0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [06:04<02:18,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36, train accu:0.9750, train loss:0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [06:14<02:07,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37, train accu:0.9900, train loss:0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [06:23<01:57,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38, train accu:0.9825, train loss:0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [06:34<01:49,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39, train accu:0.9925, train loss:0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [06:44<01:40, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40, train accu:0.9950, train loss:0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [06:54<01:30, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41, train accu:0.9925, train loss:0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [07:04<01:18,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42, train accu:0.9650, train loss:0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [07:13<01:08,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43, train accu:0.9800, train loss:0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [07:23<00:59,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44, train accu:0.9975, train loss:0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [07:34<00:50, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45, train accu:1.0000, train loss:0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [07:44<00:40, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46, train accu:1.0000, train loss:0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [07:54<00:30, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47, train accu:1.0000, train loss:0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [08:04<00:20, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48, train accu:1.0000, train loss:0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [08:13<00:09,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49, train accu:1.0000, train loss:0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [08:23<00:00, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:50, train accu:1.0000, train loss:0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    model.train()\n",
    "    for batch, (x, length, y) in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        length = length.cpu()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x, length)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.cpu().item()\n",
    "\n",
    "        #model outputs\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "        batch_cnt += 1\n",
    "    \n",
    "    train_loss = train_loss/batch_cnt\n",
    "    train_accuracy = acc_cnt/(acc_cnt+err_cnt)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    print(f\"epoch:{epoch+1}, train accu:{train_accuracy:.4f},\", f\"train loss:{train_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42092bf7",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85045cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's free memory, else we will overflow our 16GB Memory GPU\n",
    "del traindata\n",
    "del train_dataset\n",
    "del trainloader_args\n",
    "del train_dataloader\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5c9897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:43,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "testdata = []\n",
    "for _, row in tqdm(test.iterrows()):\n",
    "    testdata.append(torch.load(row['feat_path']).to(device))\n",
    "    \n",
    "test_dataset = MyDataSet(testdata, test['emotion'].tolist(), cate_dic)\n",
    "testloader_args = dict(batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, **testloader_args, \n",
    "                             collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3120f8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.7980769230769231\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "acc_cnt = 0\n",
    "err_cnt = 0\n",
    "batch_cnt = 0\n",
    "model.eval()\n",
    "\n",
    "for x, lengths, y in test_dataloader:\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    lengths = lengths.cpu()\n",
    "    logits = model(x, lengths)\n",
    "    loss = criterion(logits, y)\n",
    "    test_loss += loss.cpu().item()\n",
    "\n",
    "    out_val, out_indices = torch.max(logits, dim=1)\n",
    "    tar_indices = y\n",
    "\n",
    "    for i in range(len(out_indices)):\n",
    "        if out_indices[i] == tar_indices[i]:\n",
    "            acc_cnt += 1\n",
    "        else:\n",
    "            err_cnt += 1\n",
    "    batch_cnt += 1\n",
    "\n",
    "test_loss = test_loss/batch_cnt\n",
    "test_accuracy = acc_cnt/(acc_cnt+err_cnt)\n",
    "print(f'test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "997c700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggr.weight tensor([[[-0.1034],\n",
      "         [ 0.1640],\n",
      "         [ 0.0204],\n",
      "         [ 0.0281],\n",
      "         [-0.1704],\n",
      "         [ 0.0952],\n",
      "         [-0.1967],\n",
      "         [ 0.1936],\n",
      "         [-0.0717],\n",
      "         [ 0.2025],\n",
      "         [-0.1040],\n",
      "         [ 0.0771],\n",
      "         [-0.1338],\n",
      "         [-0.0394],\n",
      "         [-0.0678],\n",
      "         [-0.1130],\n",
      "         [ 0.1775],\n",
      "         [-0.2558],\n",
      "         [ 0.2126],\n",
      "         [ 0.0928],\n",
      "         [-0.0917],\n",
      "         [ 0.0381],\n",
      "         [-0.1356],\n",
      "         [ 0.0391]]], device='cuda:0')\n",
      "aggr.bias tensor([0.0614], device='cuda:0')\n",
      "embed.weight tensor([[-0.0032,  0.0116, -0.0621,  ..., -0.0973,  0.0091, -0.0110],\n",
      "        [-0.0298,  0.0317,  0.0605,  ...,  0.0358, -0.0440,  0.0498],\n",
      "        [ 0.0134,  0.0221, -0.0573,  ...,  0.0324, -0.0467,  0.0047],\n",
      "        ...,\n",
      "        [-0.0264, -0.0056, -0.0006,  ..., -0.0149,  0.0540,  0.0698],\n",
      "        [-0.0075,  0.0175, -0.0209,  ...,  0.0233, -0.0226,  0.0169],\n",
      "        [ 0.0506, -0.0502, -0.0167,  ..., -0.0330, -0.0742, -0.0117]],\n",
      "       device='cuda:0')\n",
      "embed.bias tensor([ 0.0394, -0.0270, -0.0404, -0.0213, -0.0168,  0.0260, -0.0350, -0.0136,\n",
      "        -0.0133, -0.0004, -0.0027, -0.0172,  0.0311, -0.0113,  0.0086,  0.0343,\n",
      "        -0.0293, -0.0632, -0.0223, -0.0609, -0.0299, -0.0334, -0.0401, -0.0127,\n",
      "         0.0218, -0.0150, -0.0330, -0.0047, -0.0353,  0.0581,  0.0038,  0.0024,\n",
      "         0.0289,  0.0231,  0.0231, -0.0168, -0.0734, -0.0012, -0.0139, -0.0010,\n",
      "         0.0304,  0.0317, -0.0176, -0.0004,  0.0461, -0.0023, -0.0162, -0.0762,\n",
      "         0.0071, -0.0397, -0.0317,  0.0188,  0.0410, -0.0447, -0.0373, -0.0698,\n",
      "         0.0123, -0.0128,  0.0409, -0.0322,  0.0157, -0.0414, -0.0595, -0.0229,\n",
      "         0.0592,  0.0043, -0.0072, -0.0630, -0.0229, -0.0281, -0.0117,  0.0138,\n",
      "         0.0218, -0.0479, -0.0249, -0.0108,  0.0159, -0.0284,  0.0350, -0.0662,\n",
      "         0.0424,  0.0388,  0.0151, -0.0329, -0.0237, -0.0396, -0.0282,  0.0629,\n",
      "         0.0294, -0.0803,  0.0840,  0.0130,  0.0324,  0.0431, -0.0498, -0.0454,\n",
      "        -0.0129, -0.0519, -0.0376,  0.0157, -0.0090, -0.0125,  0.0224, -0.0422,\n",
      "         0.0303, -0.0121, -0.0463, -0.0376,  0.0509,  0.0461,  0.0218,  0.0209,\n",
      "        -0.0130,  0.0119,  0.0106,  0.0062,  0.0658,  0.0803,  0.0481,  0.0056,\n",
      "         0.0911, -0.0217,  0.0002,  0.0141, -0.0024,  0.0343, -0.0312, -0.0240],\n",
      "       device='cuda:0')\n",
      "cnn.weight tensor([[[ 0.0658, -0.0067, -0.0227],\n",
      "         [-0.0719, -0.0649, -0.0416],\n",
      "         [ 0.0554,  0.0210,  0.0669],\n",
      "         ...,\n",
      "         [-0.0798, -0.0325, -0.0349],\n",
      "         [ 0.0105,  0.0530, -0.0319],\n",
      "         [ 0.0245, -0.0241,  0.0613]],\n",
      "\n",
      "        [[ 0.0706,  0.0935, -0.0178],\n",
      "         [-0.0566, -0.0599, -0.0392],\n",
      "         [-0.0643,  0.0204,  0.0289],\n",
      "         ...,\n",
      "         [ 0.0912,  0.0271,  0.0092],\n",
      "         [-0.0188, -0.0097,  0.0225],\n",
      "         [-0.0356, -0.0450, -0.0287]],\n",
      "\n",
      "        [[-0.0787, -0.0378, -0.0578],\n",
      "         [ 0.0358,  0.0337,  0.0405],\n",
      "         [-0.0081, -0.0182, -0.0440],\n",
      "         ...,\n",
      "         [-0.0116, -0.0483, -0.0461],\n",
      "         [ 0.0046,  0.0389,  0.0179],\n",
      "         [ 0.0592,  0.0252,  0.0011]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0573, -0.0154, -0.0023],\n",
      "         [-0.0449,  0.0256,  0.0279],\n",
      "         [-0.0099,  0.0072, -0.0750],\n",
      "         ...,\n",
      "         [ 0.0077, -0.0439,  0.0035],\n",
      "         [-0.0434, -0.0112, -0.0804],\n",
      "         [-0.0078, -0.0084,  0.0119]],\n",
      "\n",
      "        [[ 0.0095, -0.0527, -0.0003],\n",
      "         [ 0.0109,  0.0201, -0.0326],\n",
      "         [-0.0147, -0.0650, -0.0401],\n",
      "         ...,\n",
      "         [ 0.0226, -0.0139,  0.0641],\n",
      "         [ 0.0317, -0.0197,  0.0043],\n",
      "         [ 0.0479, -0.0216,  0.0269]],\n",
      "\n",
      "        [[ 0.0176,  0.0072,  0.0392],\n",
      "         [-0.0110,  0.0270,  0.0256],\n",
      "         [ 0.0241,  0.0040, -0.0219],\n",
      "         ...,\n",
      "         [-0.0969, -0.0113, -0.0280],\n",
      "         [-0.0025, -0.0265, -0.0365],\n",
      "         [-0.0242,  0.0710, -0.0043]]], device='cuda:0')\n",
      "cnn.bias tensor([-3.5258e-02, -9.1990e-03, -2.3825e-02,  1.0442e-02, -2.0325e-02,\n",
      "        -2.2304e-02,  5.2991e-02,  5.8379e-02,  4.0203e-02, -4.5042e-02,\n",
      "        -9.9516e-03,  1.7961e-02,  1.4075e-02, -7.2917e-03, -4.5796e-03,\n",
      "         8.1854e-03,  1.0445e-02, -1.9420e-02,  5.3991e-02,  4.2405e-03,\n",
      "        -2.7342e-02, -5.4120e-03,  1.8430e-02,  1.7364e-04,  3.7055e-02,\n",
      "        -1.0108e-02,  3.3565e-02,  5.8153e-03,  8.5168e-03, -5.1865e-02,\n",
      "         1.9794e-02,  5.2898e-02, -2.6170e-02, -3.2645e-02, -4.8290e-02,\n",
      "        -1.1527e-02, -4.8964e-04,  8.3604e-03, -3.6862e-02,  2.6083e-02,\n",
      "        -7.0383e-03,  2.2645e-03, -2.1786e-02,  5.4304e-02,  1.3062e-02,\n",
      "         9.8066e-03, -3.2033e-02,  4.8166e-02,  4.5175e-02, -9.0872e-03,\n",
      "         1.2186e-02, -2.9639e-02, -1.9242e-03, -1.6963e-02, -2.0539e-02,\n",
      "         4.4123e-02,  1.2229e-02, -2.2192e-02, -2.9776e-02, -5.0199e-02,\n",
      "         5.0657e-02,  4.4436e-02,  3.1013e-03, -9.1705e-03,  4.0114e-02,\n",
      "        -2.0868e-02, -1.7724e-02,  4.3941e-02,  4.8718e-03, -3.4690e-02,\n",
      "         2.7443e-02,  4.3599e-02, -5.0636e-02, -9.3371e-04, -1.8363e-02,\n",
      "         1.0646e-03,  1.7468e-02,  2.8225e-02, -2.5607e-02, -3.2656e-02,\n",
      "        -3.2155e-02,  1.4274e-02, -4.2177e-02, -3.1655e-02, -2.8104e-02,\n",
      "        -4.2630e-02, -4.8236e-02,  4.5588e-03, -2.5397e-02, -2.7661e-02,\n",
      "         1.2201e-02,  2.9536e-02,  2.2129e-02,  3.9318e-03,  6.1536e-03,\n",
      "        -7.2995e-05, -3.7171e-02,  1.5601e-02,  1.5265e-02,  4.9900e-03,\n",
      "         1.5321e-02,  1.5839e-02,  8.6546e-03, -3.9872e-02, -3.9668e-02,\n",
      "         2.9154e-03,  2.1362e-02, -4.6366e-02,  1.5497e-02,  2.2596e-03,\n",
      "         7.5810e-03, -9.2141e-03,  1.2261e-02,  1.2788e-02, -1.4400e-02,\n",
      "         4.5082e-02,  4.2577e-02, -2.5004e-02, -3.1191e-02,  4.1622e-03,\n",
      "        -2.3004e-02,  5.1527e-02,  3.4475e-03,  1.6811e-02,  1.1694e-02,\n",
      "         2.8729e-02,  1.1334e-02,  2.6121e-02], device='cuda:0')\n",
      "cnn2.weight tensor([[[ 7.8572e-02,  9.9667e-02,  6.7337e-02,  6.0349e-02,  2.4589e-02],\n",
      "         [-7.3236e-02, -6.3170e-02, -5.6673e-02, -4.0884e-02, -4.8338e-02],\n",
      "         [-4.2031e-02, -4.1061e-02,  1.2795e-03,  3.1144e-03,  9.5481e-03],\n",
      "         ...,\n",
      "         [ 3.1671e-02,  5.9094e-02,  6.1527e-03,  8.0364e-02,  2.1903e-02],\n",
      "         [ 5.3861e-03, -2.3840e-02,  4.6766e-02,  2.4341e-02,  3.2490e-02],\n",
      "         [ 5.1726e-02, -3.7474e-05,  3.6048e-02,  1.2575e-02, -1.4476e-02]],\n",
      "\n",
      "        [[ 4.9573e-02,  8.9150e-02,  7.5045e-02,  5.1799e-03,  1.0890e-02],\n",
      "         [-5.1512e-02, -7.4105e-02, -3.1600e-02, -4.6588e-02, -5.0682e-02],\n",
      "         [-2.6304e-02,  1.8312e-03, -1.5812e-02,  9.6704e-03,  3.1865e-03],\n",
      "         ...,\n",
      "         [-1.5464e-02,  8.3866e-04,  6.0130e-02,  3.4255e-02, -2.7098e-03],\n",
      "         [-1.4741e-02, -1.2123e-02,  1.9667e-02,  1.2330e-02,  2.2876e-03],\n",
      "         [ 4.8201e-02,  1.5430e-02,  4.1861e-02, -1.1517e-03,  1.5856e-02]],\n",
      "\n",
      "        [[ 1.1505e-02,  3.3858e-02,  7.8554e-02,  5.1350e-02,  3.0613e-02],\n",
      "         [-1.6370e-02, -1.1855e-02, -1.7751e-02, -5.3878e-03, -1.0849e-02],\n",
      "         [-3.2572e-02, -5.9751e-02, -6.1203e-02, -2.2265e-02, -4.9357e-02],\n",
      "         ...,\n",
      "         [ 1.0100e-03,  5.9000e-03,  3.3579e-02,  8.6188e-03,  6.5082e-02],\n",
      "         [ 4.9365e-02,  5.0719e-03,  3.1207e-02, -1.5348e-02,  1.1738e-03],\n",
      "         [ 9.5947e-03, -6.2451e-03, -5.3245e-02, -3.2586e-03, -5.3906e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.6322e-03, -4.1317e-02,  1.8396e-02, -4.4570e-03, -3.2333e-02],\n",
      "         [ 1.5933e-02, -2.3011e-02, -4.4710e-02, -4.6047e-02, -3.7918e-02],\n",
      "         [-3.6028e-02, -3.7486e-02, -1.3198e-02, -1.7732e-02, -4.3478e-02],\n",
      "         ...,\n",
      "         [-4.8587e-02, -3.3986e-02,  9.2506e-03, -1.3748e-02, -2.6822e-02],\n",
      "         [-1.3780e-02, -2.1277e-02, -1.2444e-02,  8.9538e-03, -1.0120e-02],\n",
      "         [ 6.5672e-03,  4.1526e-02, -4.6293e-03, -1.6783e-03,  4.2721e-02]],\n",
      "\n",
      "        [[-5.6385e-02, -3.3578e-02, -6.3847e-03, -8.6569e-02, -3.3021e-02],\n",
      "         [ 4.5554e-02,  2.3827e-02,  1.8179e-02,  5.5507e-02,  1.1741e-02],\n",
      "         [ 4.8961e-02,  9.9323e-03,  4.1788e-02,  1.2660e-02,  1.7256e-03],\n",
      "         ...,\n",
      "         [-7.7616e-02, -8.0561e-02, -9.9579e-02, -1.5844e-02,  1.0708e-02],\n",
      "         [ 2.2943e-03, -4.5274e-03,  3.2430e-02,  7.1343e-03,  3.2920e-02],\n",
      "         [ 3.4629e-02,  4.6807e-02, -2.9773e-02,  1.0377e-02, -4.7335e-02]],\n",
      "\n",
      "        [[-9.7935e-03,  6.2649e-03, -1.7078e-02, -2.5924e-02,  1.9127e-02],\n",
      "         [ 2.3405e-02,  1.3517e-03, -2.9892e-02,  6.8663e-03,  2.2859e-02],\n",
      "         [ 1.7644e-03,  5.3469e-02,  3.9139e-02, -5.3769e-03,  1.5403e-02],\n",
      "         ...,\n",
      "         [-4.0255e-02,  2.1357e-03, -4.9589e-02, -2.5025e-02,  1.0672e-02],\n",
      "         [-2.1460e-02, -1.7087e-02, -2.2538e-02,  1.8200e-02,  5.2860e-02],\n",
      "         [ 1.0489e-02,  4.1475e-03,  2.5988e-02, -1.2825e-03, -3.3363e-02]]],\n",
      "       device='cuda:0')\n",
      "cnn2.bias tensor([-7.5670e-03, -4.1590e-02, -2.0242e-02, -3.9800e-05,  1.9530e-03,\n",
      "        -1.8345e-03, -2.4923e-02, -2.2042e-02, -6.2844e-03,  1.4951e-02,\n",
      "         2.7986e-02, -7.6479e-03,  9.3721e-03, -9.5772e-03,  2.9291e-02,\n",
      "         3.3340e-02, -3.4306e-02,  2.2817e-02, -3.6201e-02,  1.3474e-02,\n",
      "        -3.7127e-02,  1.6761e-02, -3.3103e-02, -3.6977e-02,  3.2766e-03,\n",
      "        -1.5365e-02, -3.0831e-02,  1.3535e-02,  1.0483e-02, -2.4148e-02,\n",
      "         3.3790e-02,  3.4371e-02,  1.6407e-02,  7.5896e-03,  2.1575e-02,\n",
      "         3.5718e-02,  8.8237e-03,  1.5103e-02, -9.8515e-04,  4.4211e-03,\n",
      "        -3.1395e-02,  1.6662e-02, -1.7867e-02, -3.2853e-02,  3.4713e-02,\n",
      "         3.1173e-03,  1.7814e-02, -8.2259e-03, -2.3195e-02, -2.0498e-03,\n",
      "         2.6332e-02, -5.7805e-03, -1.9762e-02, -1.4001e-02,  2.9514e-02,\n",
      "        -1.6109e-02,  2.2605e-03,  1.3346e-02, -3.6950e-02,  2.6962e-02,\n",
      "         2.9360e-02,  2.7952e-02,  3.1541e-03,  1.8397e-03,  9.3566e-03,\n",
      "         5.3853e-03, -2.8392e-03, -1.2592e-02, -5.5758e-03, -3.3456e-02,\n",
      "        -3.1879e-02, -1.1751e-02,  1.2519e-03,  2.6917e-02, -1.5447e-02,\n",
      "        -3.6483e-02,  3.5811e-03,  2.6104e-02,  3.6627e-02,  3.3975e-03,\n",
      "        -1.4160e-02, -2.3611e-02, -4.3820e-02, -9.4619e-03, -2.5167e-02,\n",
      "         2.3788e-02,  1.7977e-02,  3.7565e-02,  1.7645e-02,  3.2224e-02,\n",
      "        -1.6263e-02,  1.8048e-02, -1.5840e-02, -2.9287e-02, -3.7657e-02,\n",
      "        -1.4742e-02,  1.8915e-02, -2.6293e-02, -2.7958e-03, -3.0544e-03,\n",
      "        -7.9858e-03, -1.0677e-02, -2.1430e-02,  2.5469e-02, -7.4248e-03,\n",
      "        -3.3158e-02, -3.4782e-02, -2.4749e-02,  4.1704e-02, -2.7668e-02,\n",
      "        -7.2631e-03, -2.8150e-02, -2.6651e-03, -8.2667e-05, -3.3921e-02,\n",
      "        -2.4057e-03,  2.4581e-02, -6.4292e-03,  3.7685e-02,  6.8655e-03,\n",
      "         1.4811e-02, -1.7640e-02, -1.9226e-02, -2.4502e-02, -1.9219e-02,\n",
      "         3.5148e-02,  1.2082e-02, -1.0145e-02], device='cuda:0')\n",
      "cnn3.weight tensor([[[-0.0130, -0.0039, -0.0178,  ...,  0.0314, -0.0203,  0.0047],\n",
      "         [-0.0383, -0.0105, -0.0399,  ..., -0.0786, -0.0414, -0.0736],\n",
      "         [-0.0220, -0.0272, -0.0350,  ..., -0.0516, -0.0212, -0.0112],\n",
      "         ...,\n",
      "         [ 0.0127,  0.0231, -0.0184,  ...,  0.0259, -0.0272,  0.0265],\n",
      "         [ 0.0164, -0.0089, -0.0034,  ...,  0.0062,  0.0254,  0.0260],\n",
      "         [-0.0220, -0.0367, -0.0106,  ..., -0.0551, -0.0304, -0.0647]],\n",
      "\n",
      "        [[-0.0347,  0.0030, -0.0493,  ..., -0.0490, -0.0262, -0.0337],\n",
      "         [ 0.0423,  0.0308,  0.0158,  ...,  0.0257,  0.0448,  0.0263],\n",
      "         [-0.0006,  0.0311, -0.0059,  ...,  0.0092,  0.0171,  0.0146],\n",
      "         ...,\n",
      "         [ 0.0289,  0.0262,  0.0368,  ...,  0.0037,  0.0156,  0.0103],\n",
      "         [-0.0304, -0.0306,  0.0066,  ...,  0.0163, -0.0310, -0.0178],\n",
      "         [-0.0242, -0.0132, -0.0352,  ..., -0.0355,  0.0065,  0.0128]],\n",
      "\n",
      "        [[ 0.0065, -0.0180,  0.0107,  ...,  0.0266,  0.0372,  0.0321],\n",
      "         [-0.0431, -0.0341, -0.0464,  ..., -0.0095, -0.0663, -0.0019],\n",
      "         [ 0.0114,  0.0278, -0.0229,  ...,  0.0355,  0.0181,  0.0178],\n",
      "         ...,\n",
      "         [-0.0671, -0.0464, -0.0266,  ..., -0.0208, -0.0158, -0.0278],\n",
      "         [ 0.0256,  0.0268, -0.0066,  ..., -0.0209, -0.0311, -0.0108],\n",
      "         [-0.0054, -0.0297,  0.0231,  ..., -0.0016,  0.0086, -0.0148]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0249,  0.0619,  0.0335,  ...,  0.0328, -0.0186,  0.0184],\n",
      "         [-0.0245, -0.0430,  0.0059,  ...,  0.0092,  0.0547,  0.0397],\n",
      "         [ 0.0395,  0.0322, -0.0343,  ...,  0.0139,  0.0214,  0.0183],\n",
      "         ...,\n",
      "         [ 0.0659,  0.1032,  0.0883,  ...,  0.1027,  0.0633,  0.0759],\n",
      "         [ 0.0105,  0.0095,  0.0306,  ..., -0.0164,  0.0190,  0.0126],\n",
      "         [ 0.0193,  0.0328,  0.0353,  ..., -0.0111, -0.0178,  0.0012]],\n",
      "\n",
      "        [[ 0.0034, -0.0581, -0.0541,  ..., -0.0210, -0.0019, -0.0234],\n",
      "         [ 0.0084, -0.0156,  0.0168,  ..., -0.0492,  0.0085, -0.0243],\n",
      "         [-0.0248, -0.0039,  0.0004,  ...,  0.0065, -0.0143,  0.0347],\n",
      "         ...,\n",
      "         [ 0.0323, -0.0254,  0.0288,  ...,  0.0173,  0.0072,  0.0026],\n",
      "         [ 0.0179,  0.0527,  0.0207,  ...,  0.0194,  0.0340,  0.0066],\n",
      "         [ 0.0133, -0.0543,  0.0046,  ..., -0.0219,  0.0072, -0.0201]],\n",
      "\n",
      "        [[ 0.1012,  0.0574,  0.0922,  ...,  0.0494,  0.0566,  0.0160],\n",
      "         [-0.0538, -0.0368, -0.0389,  ..., -0.0112, -0.0384, -0.0113],\n",
      "         [ 0.0163,  0.0076,  0.0100,  ..., -0.0209,  0.0175, -0.0159],\n",
      "         ...,\n",
      "         [-0.0125,  0.0199,  0.0481,  ...,  0.0313,  0.0237,  0.0232],\n",
      "         [-0.0192,  0.0252,  0.0290,  ...,  0.0119, -0.0238, -0.0189],\n",
      "         [ 0.0318,  0.0432,  0.0289,  ..., -0.0141, -0.0252, -0.0045]]],\n",
      "       device='cuda:0')\n",
      "cnn3.bias tensor([-2.7368e-02, -2.7939e-02, -7.7465e-03,  2.1271e-02, -4.8088e-03,\n",
      "        -1.3837e-03,  8.6587e-03,  1.2629e-02, -1.1842e-02,  7.4356e-03,\n",
      "         2.9814e-02, -2.2340e-02,  3.2816e-02,  6.6751e-03,  3.1072e-02,\n",
      "        -2.1050e-02, -3.1522e-02,  8.2445e-03, -3.5255e-02,  7.5760e-03,\n",
      "        -2.0879e-02, -6.6605e-03,  7.5878e-03, -2.3182e-02,  2.3907e-02,\n",
      "        -2.4122e-02,  3.2050e-03, -2.4603e-02,  3.4977e-02, -1.9264e-02,\n",
      "         2.2420e-02,  1.4764e-02,  1.2105e-02, -2.9994e-02, -2.4091e-02,\n",
      "         1.7091e-02, -6.7318e-03,  5.6421e-03,  5.2497e-04,  1.8715e-02,\n",
      "        -9.8641e-03,  3.3726e-03,  1.7504e-02, -2.4284e-03, -2.9221e-02,\n",
      "         2.0732e-02,  3.0784e-02, -5.7242e-03,  1.1689e-02, -2.9234e-02,\n",
      "        -8.9022e-03, -4.9732e-03,  3.0598e-02,  2.5326e-02, -2.6024e-02,\n",
      "        -3.3723e-02,  2.7581e-02,  4.6591e-03,  2.5566e-03, -1.3890e-02,\n",
      "        -1.0391e-03,  2.5497e-03, -4.1426e-03,  7.2086e-03, -1.1446e-02,\n",
      "        -2.7086e-02,  9.0890e-03, -2.4142e-02,  3.1450e-02, -2.5331e-02,\n",
      "        -1.4601e-02,  7.7507e-03, -2.9731e-02, -1.4738e-02,  7.7849e-03,\n",
      "        -1.9814e-02, -3.3277e-02,  6.8471e-03,  2.0301e-02, -1.8752e-02,\n",
      "        -1.4124e-02,  2.1677e-02, -4.6559e-03,  3.6879e-02, -9.0351e-03,\n",
      "         5.2040e-03,  1.1301e-02, -3.3415e-02, -1.1584e-02,  8.4642e-03,\n",
      "        -2.4737e-02,  1.5857e-05, -1.1581e-02,  1.8643e-02,  1.5448e-02,\n",
      "        -9.0626e-03, -9.7672e-03,  1.3513e-02,  8.5850e-03, -5.2698e-04,\n",
      "        -2.7197e-02, -2.3575e-02,  5.3558e-03, -6.9635e-03, -2.9912e-02,\n",
      "        -1.3902e-02, -1.8705e-03,  4.7181e-03, -3.4091e-02,  1.3640e-02,\n",
      "        -9.0265e-03, -1.5653e-02,  7.3192e-03,  8.9924e-03, -1.5706e-02,\n",
      "         3.2128e-02,  2.7857e-02,  2.2719e-02,  2.0237e-02, -1.8011e-02,\n",
      "         1.8011e-02,  6.3234e-03, -1.2075e-02,  1.8178e-02,  6.6914e-03,\n",
      "        -3.4307e-02,  1.0496e-02,  1.0578e-03], device='cuda:0')\n",
      "batchnorm.weight tensor([1.0132, 1.0138, 1.0023, 1.0217, 1.0093, 1.0358, 1.0324, 1.0156, 1.0014,\n",
      "        1.0227, 1.0445, 1.0269, 1.0050, 0.9922, 1.0363, 1.0191, 1.0081, 1.0367,\n",
      "        1.0289, 0.9637, 1.0023, 1.0366, 1.0168, 0.9837, 1.0286, 1.0211, 1.0232,\n",
      "        1.0258, 1.0311, 0.9999, 0.9818, 1.0320, 0.9891, 1.0399, 1.0205, 1.0163,\n",
      "        1.0446, 1.0124, 1.0014, 1.0126, 1.0432, 1.0328, 1.0156, 1.0182, 0.9984,\n",
      "        0.9313, 0.9738, 0.9853, 0.9870, 0.9910, 1.0227, 1.0195, 1.0333, 0.9946,\n",
      "        1.0047, 1.0061, 0.9923, 1.0327, 1.0126, 0.9992, 1.0382, 1.0219, 1.0097,\n",
      "        1.0210, 1.0347, 1.0392, 1.0053, 1.0204, 1.0586, 1.0064, 1.0473, 1.0100,\n",
      "        1.0118, 1.0313, 0.9913, 0.9970, 1.0345, 0.9926, 1.0285, 0.9993, 1.0317,\n",
      "        0.9954, 1.0307, 1.0481, 1.0349, 1.0262, 1.0281, 1.0068, 0.9925, 0.9469,\n",
      "        1.0193, 1.0368, 0.9808, 1.0345, 0.9986, 0.9765, 1.0525, 1.0153, 1.0227,\n",
      "        0.9981, 0.9597, 1.0345, 1.0078, 0.9965, 0.9960, 0.9697, 1.0187, 1.0176,\n",
      "        1.0059, 0.9905, 0.9987, 0.9652, 1.0258, 1.0368, 0.9907, 0.9498, 1.0423,\n",
      "        0.9560, 1.0349, 0.9594, 1.0394, 1.0385, 0.9752, 1.0067, 1.0011, 0.9619,\n",
      "        0.9909, 0.9995, 1.0121, 1.0352, 1.0251, 1.0132, 1.0173, 1.0008, 0.9792,\n",
      "        0.9781, 1.0096, 1.0082, 1.0204, 1.0380, 1.0119, 1.0037, 0.9690, 1.0038,\n",
      "        1.0143, 0.9914, 0.9988, 1.0379, 0.9865, 0.9978, 1.0745, 1.0061, 1.0206,\n",
      "        1.0368, 0.9859, 1.0035, 1.0393, 1.0262, 0.9816, 1.0054, 0.9901, 1.0003,\n",
      "        1.0040, 1.0283, 1.0220, 0.9696, 0.9874, 1.0291, 0.9764, 0.9939, 1.0259,\n",
      "        1.0383, 1.0207, 0.9899, 1.0148, 1.0293, 1.0001, 1.0021, 1.0352, 1.0225,\n",
      "        1.0315, 1.0130, 1.0536, 1.0405, 0.9856, 1.0116, 0.9869, 1.0150, 1.0410,\n",
      "        1.0194, 1.0461, 1.0037, 1.0208, 1.0060, 1.0100, 1.0144, 1.0125, 1.0474,\n",
      "        1.0104, 1.0090, 1.0127, 0.9883, 0.9794, 0.9922, 1.0406, 1.0533, 0.9806,\n",
      "        1.0381, 1.0276, 0.9863, 0.9897, 0.9766, 1.0039, 1.0257, 0.9788, 1.0068,\n",
      "        0.9581, 1.0197, 1.0150, 1.0156, 0.9823, 0.9833, 1.0084, 1.0206, 1.0021,\n",
      "        1.0248, 1.0178, 1.0447, 1.0095, 1.0163, 1.0192, 0.9665, 1.0035, 0.9996,\n",
      "        1.0003, 1.0001, 0.9948, 0.9864, 1.0442, 1.0129, 1.0405, 1.0411, 1.0013,\n",
      "        1.0039, 1.0300, 0.9957, 1.0565, 1.0234, 1.0240, 1.0194, 0.9750, 1.0130,\n",
      "        0.9765, 0.9872, 0.9905, 1.0240, 0.9615, 0.9722, 1.0319, 1.0097, 1.0190,\n",
      "        1.0097, 0.9707, 1.0370, 1.0233, 1.0127, 0.9752, 1.0208, 0.9950, 1.0333,\n",
      "        1.0228, 0.9858, 1.0228, 0.9908, 1.0060, 1.0206, 1.0016, 1.0283, 1.0127,\n",
      "        1.0219, 0.9906, 1.0004, 1.0146, 1.0565, 1.0208, 1.0228, 1.0436, 0.9952,\n",
      "        1.0306, 1.0417, 1.0262, 1.0380, 0.9944, 1.0181, 1.0183, 1.0023, 1.0005,\n",
      "        0.9795, 0.9805, 0.9944, 0.9913, 0.9940, 1.0198, 1.0076, 1.0234, 1.0078,\n",
      "        0.9973, 0.9908, 0.9882, 1.0353, 0.9994, 1.0121, 1.0170, 0.9957, 0.9914,\n",
      "        1.0094, 1.0140, 1.0354, 0.9647, 1.0360, 1.0099, 1.0099, 0.9916, 1.0108,\n",
      "        1.0243, 1.0223, 1.0263, 1.0136, 1.0373, 1.0094, 1.0210, 1.0043, 0.9967,\n",
      "        1.0254, 1.0225, 1.0219, 0.9876, 1.0054, 1.0143, 1.0327, 1.0385, 1.0141,\n",
      "        0.9973, 0.9723, 0.9598, 1.0088, 1.0182, 1.0084, 1.0113, 1.0191, 0.9970,\n",
      "        1.0405, 1.0174, 0.9962, 0.9964, 0.9915, 0.9837, 1.0305, 1.0134, 1.0004,\n",
      "        1.0086, 0.9849, 1.0186, 1.0337, 1.0100, 1.0054, 0.9870, 1.0014, 1.0226,\n",
      "        0.9999, 1.0113, 1.0040, 1.0256, 1.0159, 0.9535, 0.9957, 1.0028, 1.0036,\n",
      "        1.0275, 0.9763, 0.9731, 0.9964, 0.9673, 1.0387], device='cuda:0')\n",
      "batchnorm.bias tensor([-0.0197, -0.0333, -0.0200, -0.0066, -0.0092, -0.0210,  0.0085, -0.0137,\n",
      "        -0.0121, -0.0142, -0.0055,  0.0038, -0.0042, -0.0101,  0.0036, -0.0124,\n",
      "        -0.0003, -0.0100,  0.0175, -0.0600, -0.0163, -0.0049,  0.0235, -0.0311,\n",
      "         0.0075,  0.0073, -0.0119, -0.0019, -0.0102, -0.0362, -0.0257, -0.0088,\n",
      "        -0.0280,  0.0139, -0.0016, -0.0163,  0.0180, -0.0044, -0.0203,  0.0025,\n",
      "        -0.0002,  0.0018, -0.0078, -0.0015, -0.0280, -0.0652, -0.0088, -0.0228,\n",
      "        -0.0044, -0.0156, -0.0002, -0.0032, -0.0044, -0.0168, -0.0161, -0.0305,\n",
      "        -0.0420,  0.0208,  0.0061, -0.0230,  0.0123, -0.0079, -0.0423,  0.0010,\n",
      "         0.0192, -0.0014, -0.0213,  0.0069,  0.0149, -0.0092, -0.0080, -0.0005,\n",
      "         0.0009, -0.0055,  0.0013, -0.0128,  0.0165, -0.0197,  0.0142, -0.0370,\n",
      "         0.0014, -0.0283, -0.0060,  0.0121, -0.0068, -0.0152,  0.0127, -0.0199,\n",
      "        -0.0102, -0.0597, -0.0166,  0.0120, -0.0185,  0.0057, -0.0206, -0.0427,\n",
      "         0.0272, -0.0077,  0.0045, -0.0179, -0.0356,  0.0193, -0.0234, -0.0216,\n",
      "        -0.0083, -0.0655, -0.0007, -0.0365, -0.0278, -0.0247, -0.0300, -0.0545,\n",
      "        -0.0063,  0.0100, -0.0314, -0.0501,  0.0193, -0.0216,  0.0103, -0.0389,\n",
      "         0.0140,  0.0055, -0.0316, -0.0321, -0.0264, -0.0319, -0.0178, -0.0184,\n",
      "        -0.0209, -0.0063, -0.0059, -0.0127, -0.0036, -0.0077, -0.0361, -0.0058,\n",
      "        -0.0137, -0.0195, -0.0154,  0.0033, -0.0172, -0.0284, -0.0333, -0.0163,\n",
      "        -0.0108, -0.0145, -0.0147, -0.0315, -0.0125, -0.0054,  0.0045, -0.0230,\n",
      "         0.0063,  0.0021, -0.0099, -0.0180, -0.0024,  0.0039, -0.0363, -0.0077,\n",
      "        -0.0197, -0.0117, -0.0239,  0.0072, -0.0003, -0.0281, -0.0147,  0.0092,\n",
      "        -0.0395, -0.0141, -0.0202,  0.0243, -0.0097, -0.0336,  0.0118, -0.0095,\n",
      "        -0.0162, -0.0087,  0.0073, -0.0124, -0.0025, -0.0046,  0.0139, -0.0072,\n",
      "        -0.0046,  0.0002, -0.0268, -0.0157,  0.0185, -0.0287, -0.0058, -0.0113,\n",
      "        -0.0072, -0.0331, -0.0112,  0.0099, -0.0006,  0.0147, -0.0137, -0.0056,\n",
      "        -0.0121, -0.0073, -0.0148, -0.0003,  0.0146,  0.0104, -0.0206, -0.0047,\n",
      "         0.0008, -0.0205, -0.0071, -0.0223, -0.0224, -0.0017, -0.0264, -0.0173,\n",
      "        -0.0470,  0.0061, -0.0145,  0.0060, -0.0314, -0.0514,  0.0008, -0.0079,\n",
      "         0.0020, -0.0037,  0.0036,  0.0139, -0.0066, -0.0116, -0.0035, -0.0224,\n",
      "        -0.0029,  0.0077, -0.0170, -0.0173, -0.0199, -0.0450, -0.0017, -0.0319,\n",
      "         0.0181, -0.0070, -0.0189, -0.0205,  0.0125, -0.0179,  0.0034, -0.0024,\n",
      "         0.0219,  0.0054, -0.0296, -0.0198, -0.0435, -0.0134, -0.0332, -0.0026,\n",
      "        -0.0544, -0.0506, -0.0003, -0.0068,  0.0024, -0.0047, -0.0395, -0.0013,\n",
      "         0.0021, -0.0242, -0.0153, -0.0026, -0.0038,  0.0104, -0.0096, -0.0196,\n",
      "        -0.0317, -0.0108, -0.0229, -0.0121, -0.0156, -0.0202,  0.0053, -0.0211,\n",
      "        -0.0216, -0.0172,  0.0126,  0.0198, -0.0169,  0.0198,  0.0127, -0.0017,\n",
      "        -0.0115,  0.0129, -0.0028, -0.0084,  0.0040, -0.0009,  0.0072, -0.0277,\n",
      "        -0.0122, -0.0496, -0.0199,  0.0106, -0.0284, -0.0416, -0.0093, -0.0200,\n",
      "         0.0039, -0.0118, -0.0317, -0.0007, -0.0117, -0.0088, -0.0278, -0.0260,\n",
      "        -0.0091, -0.0038, -0.0219, -0.0045, -0.0254,  0.0122, -0.0251, -0.0198,\n",
      "        -0.0082, -0.0151, -0.0013, -0.0102,  0.0239,  0.0027, -0.0005, -0.0048,\n",
      "         0.0210, -0.0097, -0.0052, -0.0260, -0.0254,  0.0026,  0.0029,  0.0044,\n",
      "        -0.0195, -0.0262,  0.0031, -0.0033,  0.0195, -0.0015, -0.0300, -0.0296,\n",
      "        -0.0504, -0.0067, -0.0149, -0.0087,  0.0028, -0.0123, -0.0134,  0.0066,\n",
      "         0.0006, -0.0002, -0.0062, -0.0314, -0.0257, -0.0024, -0.0058, -0.0163,\n",
      "        -0.0035, -0.0176,  0.0051,  0.0060, -0.0129, -0.0105, -0.0191, -0.0107,\n",
      "        -0.0142, -0.0133, -0.0204,  0.0030,  0.0022, -0.0083, -0.0301, -0.0236,\n",
      "        -0.0216, -0.0263, -0.0005, -0.0336, -0.0423, -0.0249, -0.0318,  0.0043],\n",
      "       device='cuda:0')\n",
      "lstm.weight_ih_l0 tensor([[ 0.0039, -0.0363, -0.0208,  ..., -0.0678, -0.0453, -0.0737],\n",
      "        [ 0.0065,  0.0205,  0.0361,  ...,  0.0061,  0.0305, -0.0062],\n",
      "        [-0.0556, -0.0038, -0.0380,  ..., -0.0670, -0.0659, -0.0405],\n",
      "        ...,\n",
      "        [-0.0385, -0.0007,  0.0468,  ..., -0.0468,  0.0324,  0.0428],\n",
      "        [ 0.0211, -0.0042,  0.0136,  ...,  0.0108,  0.0131, -0.0004],\n",
      "        [ 0.0126,  0.0305,  0.0227,  ...,  0.0263,  0.0041,  0.0279]],\n",
      "       device='cuda:0')\n",
      "lstm.weight_hh_l0 tensor([[ 0.0395, -0.0067, -0.0078,  ..., -0.0127, -0.0194, -0.0107],\n",
      "        [-0.0041,  0.0419, -0.0214,  ...,  0.0488,  0.0084, -0.0006],\n",
      "        [-0.0419,  0.0177, -0.0052,  ..., -0.0114, -0.0556, -0.0409],\n",
      "        ...,\n",
      "        [-0.0117,  0.0146,  0.0035,  ...,  0.0412, -0.0052, -0.0125],\n",
      "        [ 0.0156,  0.0380, -0.0204,  ...,  0.0272, -0.0266, -0.0282],\n",
      "        [-0.0238,  0.0330, -0.0286,  ..., -0.0035,  0.0196,  0.0202]],\n",
      "       device='cuda:0')\n",
      "lstm.bias_ih_l0 tensor([-0.0121, -0.0484, -0.0342,  ...,  0.0137, -0.0417,  0.0437],\n",
      "       device='cuda:0')\n",
      "lstm.bias_hh_l0 tensor([-0.0309, -0.0474,  0.0237,  ...,  0.0083, -0.0711,  0.0479],\n",
      "       device='cuda:0')\n",
      "lstm.weight_ih_l1 tensor([[-0.0002,  0.0148,  0.0218,  ..., -0.0173,  0.0373, -0.0045],\n",
      "        [ 0.0268,  0.0129,  0.0434,  ..., -0.0612,  0.0094, -0.0023],\n",
      "        [-0.0865, -0.0130, -0.0089,  ..., -0.0361, -0.0286, -0.0306],\n",
      "        ...,\n",
      "        [-0.0290, -0.0085,  0.0145,  ...,  0.0378, -0.0319,  0.0443],\n",
      "        [-0.0393,  0.0024,  0.0099,  ...,  0.0232,  0.0363, -0.0225],\n",
      "        [ 0.0438,  0.0457,  0.0243,  ..., -0.0105, -0.0334,  0.0354]],\n",
      "       device='cuda:0')\n",
      "lstm.weight_hh_l1 tensor([[-0.0366,  0.0190,  0.0438,  ..., -0.0003,  0.0047,  0.0136],\n",
      "        [ 0.0571,  0.0161,  0.0089,  ...,  0.0374, -0.0168,  0.0588],\n",
      "        [ 0.0003, -0.0670, -0.0056,  ...,  0.0270, -0.0082,  0.0256],\n",
      "        ...,\n",
      "        [-0.0351,  0.0163, -0.0124,  ..., -0.0346, -0.0104,  0.0160],\n",
      "        [-0.0118,  0.0346, -0.0264,  ...,  0.0197, -0.0066,  0.0545],\n",
      "        [-0.0185,  0.0046, -0.0188,  ..., -0.0481, -0.0285, -0.0282]],\n",
      "       device='cuda:0')\n",
      "lstm.bias_ih_l1 tensor([ 0.0029,  0.0378, -0.0650,  ..., -0.0080, -0.0285,  0.0307],\n",
      "       device='cuda:0')\n",
      "lstm.bias_hh_l1 tensor([-0.0328,  0.0155, -0.0497,  ..., -0.0447, -0.0387,  0.0553],\n",
      "       device='cuda:0')\n",
      "linear.weight tensor([[-0.0340, -0.0018, -0.0003,  ..., -0.0500, -0.0411,  0.0780],\n",
      "        [-0.0215, -0.0547,  0.0136,  ...,  0.0322, -0.0380, -0.0027],\n",
      "        [ 0.0364,  0.0428, -0.0350,  ..., -0.0429,  0.0566, -0.0503],\n",
      "        ...,\n",
      "        [ 0.0155,  0.0282,  0.0300,  ...,  0.0060, -0.0331,  0.0489],\n",
      "        [ 0.0023,  0.0783,  0.0333,  ...,  0.0070,  0.0090, -0.0142],\n",
      "        [ 0.0426, -0.0990, -0.0641,  ...,  0.0595, -0.0487,  0.0789]],\n",
      "       device='cuda:0')\n",
      "linear.bias tensor([-0.0365, -0.0361,  0.0350, -0.0251, -0.0096, -0.0056, -0.0052],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc9b6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'models/wav2vecbase/'\n",
    "\n",
    "os.makedirs(model_path, exist_ok = True) \n",
    "\n",
    "\n",
    "torch.save({'epoch':epochs,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict()},\n",
    "            model_path + f'holdout{holdout}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
