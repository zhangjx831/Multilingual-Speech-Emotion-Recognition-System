{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f5535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "regex = re.compile(r'\\[.+\\]\\n', re.IGNORECASE)\n",
    "file_paths, file_names, emotions, audios = [], [], [], []\n",
    "emotion_map = {'anger': 'angry', 'happiness': 'happy', 'sadness': 'sad', 'fear': 'fear',\n",
    "              'disgust': 'disgust'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbaa6ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "0.12.1+cu113\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423059cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchaudio.models.wav2vec2.model.Wav2Vec2Model'>\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "bundle = torchaudio.pipelines.HUBERT_BASE\n",
    "extractor = bundle.get_model()\n",
    "print(extractor.__class__)\n",
    "print(bundle.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea12cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'session_entries.csv',\n",
       " 'fear',\n",
       " 'Tools and Documentation',\n",
       " 'disgust',\n",
       " 'sadness',\n",
       " 'happiness']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('../emotiondata/emotion_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bd4a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n"
     ]
    }
   ],
   "source": [
    "# folder_list = ['anger', 'disgust', 'fear', 'happiness', 'sadness']\n",
    "# entries = []\n",
    "# for folder in folder_list:\n",
    "#     cur_file_list = os.listdir(f'../emotiondata/emotion_data/{folder}')\n",
    "#     for i in cur_file_list:\n",
    "#         if i == 's05 (3).wav':\n",
    "#             print(\"found\")\n",
    "#             continue\n",
    "#         entries.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e0d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(entries)\n",
    "# session = []\n",
    "# equal_parts = (len(entries)-1)//5 # for equally split the entries into 5 parts\n",
    "# count = 0\n",
    "main_data_path = '../emotiondata/emotion_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c3c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 604/604 [00:00<00:00, 811714.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# #### Only Run once\n",
    "# from tqdm import tqdm \n",
    "# folder_map = {'a':'anger', 'd':'disgust', 'f':'fear', 'h':'happiness', 's':'sadness'}\n",
    "\n",
    "# file_paths = []\n",
    "# file_names = []\n",
    "# emotions = []\n",
    "# # audios = []\n",
    "# # labels = []\n",
    "\n",
    "\n",
    "# for i in tqdm(range(len(entries))):\n",
    "#     entry = entries[i]\n",
    "#     if \"wav\" not in entry:\n",
    "#         continue\n",
    "#     folder = folder_map[entry[0]]\n",
    "#     file_path = f'../emotiondata/emotion_data/{folder}/{entry}'\n",
    "#     emotion = emotion_map[folder]\n",
    "#     file_paths.append(file_path)\n",
    "#     file_names.append(entry)\n",
    "#     emotions.append(emotion)\n",
    "\n",
    "#     # assign session to it\n",
    "#     part = (count//equal_parts)%6 + 1\n",
    "#     if part == 6:\n",
    "#         part = 5\n",
    "#     session.append(part)\n",
    "#     count += 1\n",
    "\n",
    "\n",
    "# file = pd.DataFrame({'path':file_paths, 'name': file_names, 'emotion': emotions, 'session': session})\n",
    "# dataframe_path = main_data_path + '/session_entries_hubert.csv'\n",
    "# file.to_csv(dataframe_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c791adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'session_entries.csv',\n",
       " 'session_entries_hubert.csv',\n",
       " 'fear',\n",
       " 'Tools and Documentation',\n",
       " 'disgust',\n",
       " 'sadness',\n",
       " 'happiness']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir('../emotiondata/emotion_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3c00d",
   "metadata": {},
   "source": [
    "# Extract Features using Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9a5904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>emotion</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../emotiondata/emotion_data/happiness/h17 (5).wav</td>\n",
       "      <td>h17 (5).wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../emotiondata/emotion_data/happiness/h20 (2).wav</td>\n",
       "      <td>h20 (2).wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../emotiondata/emotion_data/disgust/d19 (4).wav</td>\n",
       "      <td>d19 (4).wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../emotiondata/emotion_data/sadness/s12 (4).wav</td>\n",
       "      <td>s12 (4).wav</td>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../emotiondata/emotion_data/sadness/s01 (4).wav</td>\n",
       "      <td>s01 (4).wav</td>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path         name  emotion  \\\n",
       "0  ../emotiondata/emotion_data/happiness/h17 (5).wav  h17 (5).wav    happy   \n",
       "1  ../emotiondata/emotion_data/happiness/h20 (2).wav  h20 (2).wav    happy   \n",
       "2    ../emotiondata/emotion_data/disgust/d19 (4).wav  d19 (4).wav  disgust   \n",
       "3    ../emotiondata/emotion_data/sadness/s12 (4).wav  s12 (4).wav      sad   \n",
       "4    ../emotiondata/emotion_data/sadness/s01 (4).wav  s01 (4).wav      sad   \n",
       "\n",
       "   session  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_path = main_data_path + '/session_entries.csv'\n",
    "file = pd.read_csv(dataframe_path)[['path', 'name', 'emotion', 'session']]\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6978cd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 604/604 [04:17<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "audios = []\n",
    "to_be_discarded = []\n",
    "discarded_name = []\n",
    "for i in tqdm(range(len(file['path']))):\n",
    "    path = file['path'][i]\n",
    "    wave, sr = torchaudio.load(path)\n",
    "    if sr != bundle.sample_rate:\n",
    "        wave = torchaudio.functional.resample(wave, sr, bundle.sample_rate)\n",
    "    with torch.inference_mode():\n",
    "        feature, _ = extractor.extract_features(wave)\n",
    "    \n",
    "    feature = [f[0] for f in feature]\n",
    "    audio = torch.stack(feature)\n",
    "    audios.append(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb8425",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffbf03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = 5\n",
    "train = file[file['session'] != holdout]\n",
    "train_audios = [audios[i] for i in range(len(audios)) if file['session'][i] != holdout]\n",
    "test = file[file['session'] == holdout]\n",
    "test_audios = [audios[i] for i in range(len(audios)) if file['session'][i] == holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9af2cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, audios, labels, label_transform):\n",
    "        super(MyDataSet).__init__()\n",
    "        self.audios = audios\n",
    "        self.labels = labels\n",
    "        self.label_transform = label_transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label_transform[self.labels[idx]]\n",
    "        audio = self.audios[idx]\n",
    "        length = audio.size(1)\n",
    "        return audio, length, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9aea3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(data):\n",
    "    audios, lengths, labels = zip(*data)\n",
    "    max_len = max(lengths)\n",
    "    n_ftrs = audios[0].size(2)\n",
    "    n_dims = audios[0].size(0)\n",
    "    features = torch.zeros((len(audios), n_dims, max_len, n_ftrs))\n",
    "    labels = torch.tensor(labels)\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        j, k = audios[i].size(1), audios[i].size(2)\n",
    "        features[i] = torch.cat([audios[i], torch.zeros((n_dims, max_len - j, k))], dim=1)\n",
    "\n",
    "    return features, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "545e7590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0, 'happy': 1, 'sad': 2, 'fear': 3, 'disgust': 4}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['angry', 'happy', 'sad', 'fear', 'disgust']\n",
    "cate_dic = {}\n",
    "for i, cate in enumerate(categories):\n",
    "    cate_dic[cate] = i\n",
    "cate_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87e785c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = MyDataSet(train_audios, train['emotion'].tolist(), cate_dic)\n",
    "trainloader_args = dict(batch_size=16, shuffle=True)\n",
    "train_dataloader = DataLoader(train_dataset, **trainloader_args, \n",
    "                              collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataSet(test_audios, test['emotion'].tolist(), cate_dic)\n",
    "testloader_args = dict(batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, **testloader_args, \n",
    "                             collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0ac40d",
   "metadata": {},
   "source": [
    "# 3CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27f5313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ICASSP3CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, dims = 12, embed_size=128, hidden_size=512, num_lstm_layers = 2, \n",
    "                 bidirectional = False, label_size = 5):\n",
    "        super().__init__()\n",
    "        self.n_layers = num_lstm_layers \n",
    "        self.hidden = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.aggr = nn.Conv1d(in_channels=dims, out_channels=1, kernel_size=1)\n",
    "        \n",
    "        self.embed = nn.Linear(in_features = vocab_size, out_features = embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(3 * embed_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = 3 * embed_size, \n",
    "                            hidden_size = hidden_size, \n",
    "                            num_layers = num_lstm_layers, \n",
    "                            bidirectional = bidirectional)\n",
    "\n",
    "        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n",
    "                                out_features = label_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "        n, d, b, t = x.size(0), x.size(1), x.size(2), x.size(3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        input = self.aggr(x)\n",
    "        input = torch.reshape(input, (n, b, t))\n",
    "        input = self.embed(input)\n",
    "\n",
    "        batch_size = input.size(0)\n",
    "        input = input.transpose(1,2)    # (B,T,H) -> (B,H,T)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n",
    "            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n",
    "        else:\n",
    "            h_n = hn[-1]\n",
    "\n",
    "        logits = self.linear(h_n)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37923d98",
   "metadata": {},
   "source": [
    "# Train Each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "328040c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                       | 0/50 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:66] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 375128064 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7686/247014599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mbatch_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7686/2916522793.py\u001b[0m in \u001b[0;36mcollate_indic\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ftrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:66] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 375128064 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "\n",
    "model = ICASSP3CNN(768)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 50\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    model.train()\n",
    "    for batch, (x, length, y) in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x, length)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.cpu().item()\n",
    "\n",
    "        #model outputs\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "        batch_cnt += 1\n",
    "    \n",
    "    train_loss = train_loss/batch_cnt\n",
    "    train_accuracy = acc_cnt/(acc_cnt+err_cnt)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    print(f\"epoch:{epoch+1}, train accu:{train_accuracy:.4f},\", f\"train loss:{train_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1562d",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "acc_cnt = 0\n",
    "err_cnt = 0\n",
    "batch_cnt = 0\n",
    "model.eval()\n",
    "\n",
    "for x, lengths, y in test_dataloader:\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logits = model(x, lengths)\n",
    "    loss = criterion(logits, y)\n",
    "    test_loss += loss.cpu().item()\n",
    "\n",
    "    out_val, out_indices = torch.max(logits, dim=1)\n",
    "    tar_indices = y\n",
    "\n",
    "    for i in range(len(out_indices)):\n",
    "        if out_indices[i] == tar_indices[i]:\n",
    "            acc_cnt += 1\n",
    "        else:\n",
    "            err_cnt += 1\n",
    "    batch_cnt += 1\n",
    "\n",
    "test_loss = test_loss/batch_cnt\n",
    "test_accuracy = acc_cnt/(acc_cnt+err_cnt)\n",
    "print(f'test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb40d4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggr.weight tensor([[[ 0.1137],\n",
      "         [ 0.2442],\n",
      "         [-0.0252],\n",
      "         [-0.1471],\n",
      "         [ 0.1538],\n",
      "         [ 0.0736],\n",
      "         [-0.1341],\n",
      "         [ 0.2401],\n",
      "         [-0.0539],\n",
      "         [-0.2481],\n",
      "         [-0.0961],\n",
      "         [-0.0603]]], device='cuda:0')\n",
      "aggr.bias tensor([-0.0231], device='cuda:0')\n",
      "embed.weight tensor([[-0.0246, -0.0017, -0.0153,  ..., -0.0142,  0.0716, -0.0584],\n",
      "        [-0.0008, -0.0021, -0.0276,  ..., -0.0100,  0.0158, -0.0469],\n",
      "        [-0.0290, -0.0535,  0.0291,  ..., -0.0472,  0.0628,  0.0445],\n",
      "        ...,\n",
      "        [ 0.0323, -0.0050, -0.0317,  ...,  0.0242, -0.0329,  0.0098],\n",
      "        [ 0.0022, -0.0889, -0.0184,  ..., -0.0075, -0.0605, -0.0528],\n",
      "        [-0.0396,  0.0170,  0.0568,  ...,  0.0118,  0.0685,  0.0028]],\n",
      "       device='cuda:0')\n",
      "embed.bias tensor([ 7.5448e-02,  1.9158e-02,  1.3492e-02,  6.3024e-02, -4.9201e-03,\n",
      "        -1.1857e-02,  6.7821e-03, -1.0039e-02,  7.4001e-02, -4.8564e-02,\n",
      "         3.9853e-02, -2.5069e-02, -1.7454e-02, -2.2599e-02, -3.0382e-02,\n",
      "         4.9609e-02,  1.9422e-02, -2.8740e-02,  8.8329e-03,  8.3936e-03,\n",
      "         1.1973e-02, -4.6975e-02,  4.1276e-02,  4.5122e-02,  4.2191e-02,\n",
      "         2.6446e-02,  7.3527e-02,  2.0780e-02, -3.8693e-02, -2.0390e-02,\n",
      "         1.1678e-02, -5.5917e-02,  8.6141e-02, -6.4460e-02, -5.1811e-02,\n",
      "        -3.0997e-02, -4.3623e-03,  3.8879e-02,  4.5334e-02,  9.7575e-03,\n",
      "        -2.9278e-03, -1.6385e-02,  1.0103e-02,  1.3035e-02, -2.7943e-02,\n",
      "        -6.7440e-03,  5.1701e-03, -3.4112e-02,  3.7493e-02, -6.5353e-02,\n",
      "        -4.0663e-02,  1.6066e-02, -2.5292e-02, -1.9713e-02,  6.6193e-02,\n",
      "         2.9935e-02,  2.1861e-02, -3.5073e-02, -1.0118e-02,  4.4493e-03,\n",
      "         3.8530e-02,  1.6665e-02,  1.2853e-02,  1.4964e-02,  1.0809e-02,\n",
      "        -3.7098e-02, -5.0214e-02,  6.2585e-03,  8.1419e-03,  3.8378e-02,\n",
      "        -1.2151e-02,  3.6618e-02, -3.7031e-02,  4.8091e-02, -3.5152e-02,\n",
      "        -8.1423e-03, -7.1419e-02,  2.2081e-02, -4.9299e-02,  6.3889e-05,\n",
      "         1.4102e-02,  5.4058e-02,  3.8595e-03, -5.7988e-02,  1.0258e-02,\n",
      "         5.5458e-02,  4.6978e-02,  2.7368e-02,  9.1217e-03,  5.4353e-02,\n",
      "        -2.7395e-02,  3.2420e-03,  4.9578e-03,  4.2044e-03, -2.5148e-02,\n",
      "        -2.4740e-02, -1.5420e-02, -1.3577e-02, -2.9419e-02,  6.3057e-02,\n",
      "        -5.4346e-02,  2.8545e-02, -4.2070e-03, -2.4071e-02, -1.6540e-02,\n",
      "        -4.0748e-02,  3.1733e-02,  4.7054e-02, -6.8770e-02,  4.9663e-02,\n",
      "        -7.0509e-03,  1.9716e-02,  4.1319e-02,  1.9947e-02, -6.2402e-02,\n",
      "        -5.6663e-02,  3.0176e-02, -2.3868e-02,  3.2212e-02,  3.6965e-02,\n",
      "         8.1314e-02, -3.2644e-02, -3.1273e-02, -1.1225e-02,  2.6493e-02,\n",
      "         1.6976e-02,  1.5887e-02,  5.8104e-04], device='cuda:0')\n",
      "cnn.weight tensor([[[-0.0617, -0.0545, -0.0670],\n",
      "         [ 0.0255,  0.0034,  0.0235],\n",
      "         [-0.0675,  0.0208, -0.0085],\n",
      "         ...,\n",
      "         [-0.0386,  0.0296,  0.0422],\n",
      "         [-0.0422, -0.0655, -0.0475],\n",
      "         [-0.0054, -0.0161,  0.0153]],\n",
      "\n",
      "        [[ 0.0336,  0.0033,  0.0737],\n",
      "         [ 0.0619,  0.0031, -0.0013],\n",
      "         [-0.0203, -0.0602, -0.0309],\n",
      "         ...,\n",
      "         [ 0.0598,  0.0350,  0.0391],\n",
      "         [-0.0683, -0.0037,  0.0609],\n",
      "         [ 0.0040,  0.0178, -0.0359]],\n",
      "\n",
      "        [[-0.0055, -0.0490, -0.0402],\n",
      "         [ 0.0980,  0.0873,  0.0865],\n",
      "         [-0.0263, -0.0421, -0.0585],\n",
      "         ...,\n",
      "         [ 0.0156,  0.0766,  0.0362],\n",
      "         [-0.0249,  0.0192, -0.0562],\n",
      "         [ 0.0291,  0.0210, -0.0093]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0056,  0.0099, -0.0296],\n",
      "         [ 0.0888, -0.0009,  0.0308],\n",
      "         [-0.0139, -0.0298, -0.0690],\n",
      "         ...,\n",
      "         [ 0.0064,  0.0665,  0.0577],\n",
      "         [-0.0077,  0.0190, -0.0232],\n",
      "         [-0.0127,  0.0513,  0.0304]],\n",
      "\n",
      "        [[-0.0573, -0.0551, -0.0325],\n",
      "         [-0.1093, -0.0603, -0.0772],\n",
      "         [ 0.0238, -0.0153,  0.0137],\n",
      "         ...,\n",
      "         [ 0.0020,  0.0245, -0.0247],\n",
      "         [-0.0299, -0.0593, -0.0215],\n",
      "         [ 0.0115,  0.0430,  0.0235]],\n",
      "\n",
      "        [[ 0.0068,  0.0374, -0.0180],\n",
      "         [-0.0059, -0.0229,  0.0483],\n",
      "         [-0.0617, -0.0531, -0.0684],\n",
      "         ...,\n",
      "         [ 0.0005, -0.0044, -0.0022],\n",
      "         [-0.0054,  0.0689,  0.0483],\n",
      "         [ 0.0020,  0.0170,  0.0271]]], device='cuda:0')\n",
      "cnn.bias tensor([-0.0219, -0.0122, -0.0311, -0.0507, -0.0367,  0.0076, -0.0066,  0.0441,\n",
      "         0.0524,  0.0180,  0.0144, -0.0177,  0.0215,  0.0186,  0.0463, -0.0433,\n",
      "         0.0013, -0.0469, -0.0293, -0.0064, -0.0431,  0.0397,  0.0375,  0.0086,\n",
      "        -0.0256,  0.0510, -0.0176,  0.0020,  0.0002, -0.0456,  0.0416, -0.0281,\n",
      "         0.0049, -0.0527, -0.0343,  0.0286, -0.0284,  0.0334,  0.0541, -0.0106,\n",
      "         0.0042,  0.0336, -0.0254,  0.0053,  0.0481, -0.0107, -0.0078, -0.0526,\n",
      "        -0.0054,  0.0427,  0.0574,  0.0289, -0.0210,  0.0065, -0.0465, -0.0334,\n",
      "         0.0069,  0.0379,  0.0204,  0.0171, -0.0435,  0.0332,  0.0027, -0.0189,\n",
      "         0.0395,  0.0312, -0.0288,  0.0391,  0.0054,  0.0480, -0.0337,  0.0206,\n",
      "        -0.0442,  0.0167,  0.0249, -0.0246,  0.0137, -0.0400, -0.0097, -0.0415,\n",
      "        -0.0195, -0.0245, -0.0296, -0.0163,  0.0051, -0.0407,  0.0176,  0.0306,\n",
      "        -0.0243,  0.0468,  0.0177, -0.0388,  0.0095, -0.0320,  0.0261,  0.0279,\n",
      "        -0.0081, -0.0441,  0.0171, -0.0083, -0.0293,  0.0195, -0.0242, -0.0167,\n",
      "        -0.0026,  0.0229, -0.0222, -0.0020, -0.0218,  0.0005, -0.0391,  0.0426,\n",
      "         0.0024,  0.0298, -0.0250, -0.0027,  0.0214, -0.0305,  0.0361, -0.0071,\n",
      "         0.0023, -0.0383, -0.0083, -0.0190,  0.0176,  0.0272,  0.0534, -0.0328],\n",
      "       device='cuda:0')\n",
      "cnn2.weight tensor([[[ 6.9194e-03,  5.3083e-02,  2.6294e-02,  5.9045e-02,  3.2052e-02],\n",
      "         [-2.9105e-03, -1.0589e-02,  5.1616e-04, -4.2910e-02, -2.1306e-03],\n",
      "         [ 3.6386e-02,  6.8340e-02,  7.9923e-02,  5.8183e-02,  1.4496e-02],\n",
      "         ...,\n",
      "         [-4.5688e-02, -8.5469e-02, -1.1101e-01, -6.1635e-02, -3.7206e-02],\n",
      "         [ 2.3962e-02, -4.2227e-02, -6.3690e-03, -1.0497e-02, -9.1157e-03],\n",
      "         [ 4.5425e-02, -4.1330e-03,  5.0827e-02,  1.6067e-02, -3.3126e-05]],\n",
      "\n",
      "        [[-5.1033e-02, -3.8894e-02,  6.2686e-04, -4.0589e-02, -5.4987e-02],\n",
      "         [ 2.6245e-02,  9.6894e-03, -4.1862e-02, -2.8308e-02, -4.3358e-02],\n",
      "         [ 2.3143e-03,  3.4211e-02,  1.6545e-02,  3.6238e-02,  1.7749e-03],\n",
      "         ...,\n",
      "         [-4.1302e-02, -7.2701e-03,  6.1788e-03,  1.3057e-02, -9.8702e-03],\n",
      "         [-2.6311e-02,  1.5073e-02, -3.8529e-02, -2.1002e-02, -3.2569e-02],\n",
      "         [-7.3322e-03, -3.4820e-02,  2.7200e-02, -2.2291e-02,  2.7495e-02]],\n",
      "\n",
      "        [[-5.1388e-02, -3.3814e-02,  4.5299e-03, -1.9613e-02,  3.2454e-03],\n",
      "         [-6.9694e-02, -3.7692e-02, -6.0624e-02, -3.6906e-02, -2.7003e-02],\n",
      "         [ 1.2298e-02,  2.1656e-02,  2.0075e-02, -2.8689e-02, -3.8800e-02],\n",
      "         ...,\n",
      "         [ 1.2565e-02,  9.3569e-03,  5.4670e-05,  1.7663e-03, -2.9606e-02],\n",
      "         [-1.6501e-02, -2.8851e-02, -9.1605e-02, -4.7305e-02, -1.0125e-01],\n",
      "         [ 3.1027e-02,  1.4385e-02, -1.9380e-02, -3.5808e-03,  6.7919e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0919e-01, -3.1983e-02, -1.2047e-02, -3.6753e-03, -5.2126e-02],\n",
      "         [-6.2192e-02, -1.1825e-02,  1.5920e-02, -1.1132e-02, -2.4852e-02],\n",
      "         [ 1.3185e-02, -1.0962e-02, -2.8930e-02,  4.1977e-02,  9.8471e-04],\n",
      "         ...,\n",
      "         [-2.1313e-02, -1.7343e-02, -2.4569e-02, -3.7916e-03,  1.5780e-02],\n",
      "         [ 1.7280e-02,  1.7501e-03,  7.2690e-04,  2.6420e-02,  3.9627e-03],\n",
      "         [ 9.3918e-04, -1.6703e-02, -2.4069e-02,  3.5006e-02, -1.6064e-02]],\n",
      "\n",
      "        [[ 5.0078e-02,  5.1042e-02,  4.0962e-02, -5.3898e-03,  9.7395e-03],\n",
      "         [ 7.6633e-02,  5.8146e-02,  4.5449e-02,  3.0798e-02,  1.8652e-02],\n",
      "         [ 2.6606e-02,  1.7901e-02, -3.1029e-02, -3.4656e-02, -4.1532e-02],\n",
      "         ...,\n",
      "         [ 5.8185e-02,  8.5749e-02,  7.5672e-02,  5.7667e-03,  2.9604e-02],\n",
      "         [-1.4435e-02, -1.6939e-05,  1.8344e-02, -2.8953e-02, -2.9169e-04],\n",
      "         [-4.7073e-03,  1.8075e-02, -5.5120e-02, -5.7153e-03,  6.3436e-04]],\n",
      "\n",
      "        [[ 1.9973e-02,  1.2823e-02, -4.9952e-02, -2.6952e-03, -2.2704e-02],\n",
      "         [-1.0745e-02, -1.8057e-02,  1.5540e-02, -2.0121e-02,  1.1253e-03],\n",
      "         [-5.6028e-02, -6.5630e-02, -7.8442e-02, -4.6981e-02, -2.5181e-02],\n",
      "         ...,\n",
      "         [ 1.8659e-02,  1.4232e-02, -3.2726e-02, -1.6157e-02,  1.3645e-02],\n",
      "         [-6.0831e-02, -2.0698e-02, -4.6644e-02, -3.6829e-02, -7.1562e-02],\n",
      "         [ 3.2166e-02, -5.3687e-02, -2.6694e-02, -3.4949e-02,  1.9337e-02]]],\n",
      "       device='cuda:0')\n",
      "cnn2.bias tensor([-0.0067,  0.0348, -0.0256, -0.0072, -0.0264, -0.0235, -0.0216,  0.0062,\n",
      "         0.0279, -0.0104,  0.0036, -0.0130, -0.0468,  0.0373, -0.0332, -0.0258,\n",
      "        -0.0223, -0.0373,  0.0135, -0.0038, -0.0182,  0.0179,  0.0041,  0.0381,\n",
      "        -0.0209,  0.0226,  0.0379,  0.0197, -0.0292,  0.0202,  0.0216, -0.0301,\n",
      "        -0.0120,  0.0444, -0.0157,  0.0046,  0.0220, -0.0335,  0.0176,  0.0234,\n",
      "        -0.0442,  0.0338,  0.0204,  0.0053,  0.0354, -0.0141,  0.0061,  0.0091,\n",
      "        -0.0077, -0.0129,  0.0134,  0.0144,  0.0202, -0.0437,  0.0375,  0.0044,\n",
      "        -0.0334, -0.0089,  0.0458,  0.0254, -0.0319, -0.0156,  0.0093,  0.0094,\n",
      "         0.0034, -0.0020, -0.0235, -0.0093, -0.0233,  0.0417, -0.0102,  0.0141,\n",
      "         0.0017, -0.0204, -0.0515,  0.0306,  0.0356,  0.0064,  0.0223, -0.0086,\n",
      "         0.0061, -0.0091,  0.0215,  0.0141,  0.0337, -0.0301, -0.0416,  0.0338,\n",
      "         0.0129, -0.0110, -0.0344,  0.0113,  0.0200,  0.0477,  0.0096,  0.0079,\n",
      "        -0.0113, -0.0263,  0.0344,  0.0037, -0.0346, -0.0159,  0.0247, -0.0150,\n",
      "        -0.0051,  0.0164,  0.0018, -0.0278, -0.0174, -0.0030, -0.0064,  0.0125,\n",
      "        -0.0163, -0.0073, -0.0241,  0.0106,  0.0237,  0.0205,  0.0402, -0.0315,\n",
      "        -0.0319, -0.0109,  0.0333, -0.0065,  0.0178,  0.0050, -0.0400,  0.0198],\n",
      "       device='cuda:0')\n",
      "cnn3.weight tensor([[[-6.9428e-02, -3.9510e-02, -1.6611e-02,  ...,  5.0508e-03,\n",
      "           2.3438e-03, -3.8075e-02],\n",
      "         [-3.0803e-02, -4.8829e-02, -3.0465e-02,  ...,  1.4071e-02,\n",
      "          -1.4533e-02, -3.6002e-02],\n",
      "         [-2.0210e-02, -3.7733e-02, -6.2695e-02,  ..., -2.3557e-02,\n",
      "          -3.6714e-02, -4.0808e-02],\n",
      "         ...,\n",
      "         [ 3.3866e-02,  4.9948e-02,  3.0127e-02,  ...,  1.1678e-02,\n",
      "           2.0793e-02, -1.1124e-02],\n",
      "         [-4.3876e-02, -5.9652e-02, -5.6971e-02,  ..., -4.2807e-02,\n",
      "          -2.5841e-02, -1.8014e-02],\n",
      "         [-3.7983e-02, -2.6535e-02,  7.7961e-03,  ..., -6.7667e-03,\n",
      "           2.3580e-02, -4.6385e-02]],\n",
      "\n",
      "        [[ 6.1285e-03,  1.7960e-02,  4.5776e-02,  ...,  3.2528e-03,\n",
      "           3.1468e-02, -1.7898e-02],\n",
      "         [-2.9038e-02, -2.9394e-02, -3.2338e-02,  ..., -4.2661e-02,\n",
      "          -2.1100e-02, -3.0560e-02],\n",
      "         [-5.9153e-02, -5.7163e-02, -3.5743e-02,  ..., -5.8130e-02,\n",
      "           1.4781e-02, -4.6005e-02],\n",
      "         ...,\n",
      "         [-2.6985e-02, -5.3409e-02, -4.5684e-02,  ..., -4.6772e-02,\n",
      "          -9.8697e-03,  1.5280e-02],\n",
      "         [-1.9230e-02,  1.1296e-02, -3.6930e-02,  ..., -3.3439e-02,\n",
      "          -1.1267e-02,  1.2420e-02],\n",
      "         [-8.3771e-03,  1.5422e-02, -3.6203e-02,  ..., -2.0915e-03,\n",
      "           2.4237e-02,  5.1850e-02]],\n",
      "\n",
      "        [[-3.7177e-03,  8.9068e-03, -1.7606e-03,  ...,  2.7489e-02,\n",
      "           2.6783e-03,  3.2457e-02],\n",
      "         [-7.7005e-02, -4.4668e-02, -1.9717e-03,  ...,  3.4831e-02,\n",
      "          -1.0049e-02, -3.7547e-03],\n",
      "         [-3.7958e-02, -2.9473e-02, -3.7405e-03,  ..., -4.6709e-02,\n",
      "          -3.9371e-03,  9.6905e-03],\n",
      "         ...,\n",
      "         [-6.4455e-02, -6.3530e-02, -1.1348e-01,  ..., -4.0547e-02,\n",
      "          -6.8982e-02, -1.9952e-02],\n",
      "         [ 2.2562e-02,  6.4554e-02,  5.3397e-02,  ...,  4.9826e-02,\n",
      "           4.6195e-02,  2.9760e-02],\n",
      "         [-3.7119e-03,  2.0614e-02, -3.4271e-04,  ..., -1.8471e-02,\n",
      "           1.3018e-02,  2.0302e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.1579e-03,  2.0342e-02, -1.2466e-02,  ..., -1.7514e-04,\n",
      "          -1.2896e-03, -9.0997e-03],\n",
      "         [-3.0425e-02, -5.5350e-02,  1.4065e-02,  ..., -1.4314e-02,\n",
      "           2.7643e-03, -3.4580e-03],\n",
      "         [-2.6977e-02, -5.4896e-02, -5.8080e-02,  ..., -4.1744e-02,\n",
      "          -1.9148e-02, -3.5361e-02],\n",
      "         ...,\n",
      "         [-2.0466e-02,  3.3759e-03,  1.5535e-02,  ..., -2.0924e-02,\n",
      "           4.0802e-02,  8.1470e-03],\n",
      "         [-5.8251e-02,  9.7719e-03,  7.1822e-03,  ..., -4.0913e-02,\n",
      "          -4.6550e-03, -5.7163e-02],\n",
      "         [ 2.3456e-02,  4.7602e-02, -9.8228e-03,  ..., -1.0107e-02,\n",
      "          -2.2228e-02, -6.2257e-02]],\n",
      "\n",
      "        [[ 8.4538e-03, -2.6480e-02,  2.2971e-02,  ..., -3.3258e-02,\n",
      "          -4.2929e-02, -3.3074e-03],\n",
      "         [ 4.2318e-03,  1.9197e-02, -2.3340e-02,  ..., -1.1302e-02,\n",
      "          -1.6863e-02,  1.7490e-02],\n",
      "         [ 2.3369e-02, -5.7138e-05, -6.8442e-03,  ..., -1.5485e-02,\n",
      "          -2.8597e-02,  6.7511e-03],\n",
      "         ...,\n",
      "         [-6.9796e-03, -1.1508e-02,  2.4726e-02,  ..., -2.0494e-02,\n",
      "          -3.5729e-02, -3.1449e-02],\n",
      "         [-2.1484e-03,  1.5011e-03, -2.7254e-03,  ...,  1.6074e-02,\n",
      "           1.4024e-02,  4.7130e-02],\n",
      "         [ 6.2250e-03,  7.8946e-03, -3.1849e-02,  ..., -1.6444e-02,\n",
      "           1.9282e-02, -6.2699e-03]],\n",
      "\n",
      "        [[ 3.3404e-03,  8.6292e-03, -1.6948e-03,  ...,  9.1459e-03,\n",
      "          -3.5371e-02, -1.0831e-02],\n",
      "         [-4.9906e-03,  8.2468e-03, -2.9237e-02,  ...,  1.3680e-02,\n",
      "          -7.6042e-03,  2.5037e-02],\n",
      "         [ 8.5948e-02,  9.8440e-02,  5.8757e-02,  ...,  1.2322e-03,\n",
      "           2.2865e-02,  1.1875e-02],\n",
      "         ...,\n",
      "         [-7.5584e-02, -4.1315e-02, -1.0700e-02,  ...,  4.0575e-02,\n",
      "           1.4288e-02,  6.6070e-03],\n",
      "         [ 2.6271e-02,  2.8563e-02,  1.9029e-02,  ...,  2.4757e-02,\n",
      "           6.8632e-02,  6.6635e-02],\n",
      "         [ 5.1339e-02, -4.7871e-03,  4.6594e-03,  ...,  8.3912e-03,\n",
      "           4.7110e-02,  3.4538e-02]]], device='cuda:0')\n",
      "cnn3.bias tensor([ 0.0047,  0.0283, -0.0238, -0.0075,  0.0054,  0.0202, -0.0024, -0.0164,\n",
      "         0.0064,  0.0132, -0.0121, -0.0326,  0.0032, -0.0279,  0.0289,  0.0229,\n",
      "        -0.0009, -0.0296, -0.0237,  0.0159, -0.0096,  0.0283,  0.0178, -0.0131,\n",
      "        -0.0069,  0.0380,  0.0187, -0.0023,  0.0315,  0.0228,  0.0274,  0.0202,\n",
      "        -0.0166,  0.0107,  0.0111,  0.0257, -0.0303, -0.0099,  0.0100, -0.0212,\n",
      "        -0.0433, -0.0098, -0.0071,  0.0277,  0.0037, -0.0256,  0.0138,  0.0016,\n",
      "        -0.0296, -0.0377,  0.0069,  0.0432, -0.0064,  0.0027,  0.0184,  0.0032,\n",
      "        -0.0117, -0.0002, -0.0131,  0.0149, -0.0062,  0.0235, -0.0291,  0.0362,\n",
      "        -0.0279, -0.0053, -0.0241, -0.0270,  0.0460, -0.0340, -0.0104,  0.0199,\n",
      "         0.0131,  0.0021, -0.0046,  0.0278,  0.0280, -0.0223, -0.0228,  0.0160,\n",
      "         0.0201, -0.0145,  0.0068, -0.0123,  0.0228, -0.0125,  0.0346, -0.0163,\n",
      "        -0.0051,  0.0074,  0.0329, -0.0105,  0.0324,  0.0212,  0.0167,  0.0086,\n",
      "         0.0260, -0.0160,  0.0005,  0.0228,  0.0294,  0.0173, -0.0253,  0.0292,\n",
      "         0.0226, -0.0033,  0.0096,  0.0051,  0.0288,  0.0116,  0.0295,  0.0172,\n",
      "         0.0024, -0.0067,  0.0324, -0.0193,  0.0053, -0.0002,  0.0125, -0.0330,\n",
      "         0.0030,  0.0105,  0.0099, -0.0006, -0.0268,  0.0137, -0.0156, -0.0026],\n",
      "       device='cuda:0')\n",
      "batchnorm.weight tensor([1.0185, 0.9689, 0.9851, 0.9945, 0.9257, 0.9900, 0.9947, 0.9951, 1.0012,\n",
      "        1.0004, 1.0049, 1.0490, 1.0401, 0.9982, 1.0149, 1.0137, 0.9981, 1.0162,\n",
      "        0.9955, 1.0043, 0.9857, 0.9867, 0.9972, 1.0284, 1.0172, 1.0279, 1.0106,\n",
      "        1.0068, 1.0001, 1.0089, 1.0221, 1.0199, 0.9739, 1.0277, 1.0061, 0.9574,\n",
      "        1.0022, 0.9645, 0.9563, 1.0267, 1.0354, 1.0059, 1.0414, 0.9625, 0.9972,\n",
      "        0.9750, 0.9922, 1.0008, 1.0395, 1.0086, 0.9882, 0.9601, 0.9507, 1.0178,\n",
      "        0.9675, 0.9742, 0.9606, 0.9812, 0.9404, 1.0315, 0.9653, 0.9840, 1.0028,\n",
      "        0.9671, 1.0296, 0.9947, 1.0154, 0.9641, 1.0058, 1.0092, 1.0032, 1.0028,\n",
      "        0.9508, 0.9188, 1.0187, 0.9758, 0.9935, 1.0075, 1.0005, 0.9724, 1.0135,\n",
      "        0.9844, 0.9994, 0.9128, 0.9969, 1.0396, 0.9803, 0.9950, 0.9878, 0.9997,\n",
      "        0.9767, 1.0219, 0.9908, 0.9462, 0.9492, 0.9936, 0.9923, 1.0224, 1.0383,\n",
      "        1.0147, 0.9777, 0.9921, 0.9980, 0.9845, 1.0201, 1.0218, 1.0383, 0.9998,\n",
      "        0.9719, 1.0105, 1.0010, 0.9907, 1.0061, 1.0079, 0.9639, 1.0114, 1.0352,\n",
      "        0.9857, 0.9342, 1.0338, 0.9746, 0.9902, 0.9920, 0.9853, 1.0176, 1.0304,\n",
      "        0.9834, 1.0156, 0.9976, 0.9315, 0.9998, 1.0279, 0.9174, 0.9666, 1.0310,\n",
      "        1.0310, 0.9911, 0.9830, 1.0170, 1.0057, 0.9984, 0.9959, 0.9666, 1.0056,\n",
      "        1.0165, 1.0020, 0.9694, 1.0217, 0.9637, 0.9990, 0.9887, 1.0109, 0.9945,\n",
      "        0.9539, 0.9694, 1.0261, 0.9745, 0.9990, 1.0099, 0.9779, 1.0162, 0.9985,\n",
      "        0.9673, 0.9839, 1.0010, 0.9933, 1.0212, 0.9766, 1.0330, 0.9948, 1.0280,\n",
      "        1.0118, 1.0039, 1.0271, 1.0474, 1.0361, 1.0222, 0.9953, 0.9932, 0.9668,\n",
      "        1.0145, 0.9329, 1.0269, 1.0116, 1.0159, 0.9527, 1.0268, 0.9268, 0.9972,\n",
      "        1.0027, 0.9743, 1.0071, 1.0278, 1.0137, 0.9623, 0.9989, 0.9961, 1.0219,\n",
      "        1.0090, 1.0100, 0.9868, 1.0287, 1.0156, 1.0081, 0.9543, 1.0194, 0.9901,\n",
      "        1.0051, 1.0106, 1.0221, 1.0101, 1.0028, 1.0230, 1.0275, 0.9833, 1.0351,\n",
      "        1.0148, 0.9790, 1.0188, 0.9371, 0.9425, 0.9991, 1.0027, 1.0242, 0.9850,\n",
      "        0.9760, 0.9999, 0.9671, 1.0043, 1.0101, 1.0126, 1.0094, 0.9750, 1.0164,\n",
      "        1.0122, 0.9595, 0.9559, 1.0137, 1.0341, 0.9583, 1.0395, 0.9531, 0.9239,\n",
      "        0.9968, 0.9748, 1.0287, 1.0280, 1.0193, 0.9945, 1.0106, 1.0038, 1.0176,\n",
      "        1.0401, 1.0068, 1.0232, 0.9877, 1.0134, 1.0168, 1.0225, 1.0043, 1.0400,\n",
      "        1.0061, 0.9828, 1.0337, 1.0004, 0.9730, 1.0405, 0.9730, 1.0314, 1.0060,\n",
      "        0.9770, 1.0206, 0.9839, 1.0235, 1.0048, 0.9300, 0.9251, 1.0193, 1.0300,\n",
      "        0.9775, 0.9909, 0.9756, 1.0188, 1.0113, 1.0258, 1.0257, 1.0164, 0.9998,\n",
      "        0.9750, 1.0415, 1.0067, 1.0297, 1.0342, 1.0305, 0.9993, 0.9904, 0.9781,\n",
      "        0.9963, 1.0103, 1.0155, 0.9917, 0.9394, 1.0125, 1.0313, 1.0054, 0.9935,\n",
      "        0.9832, 1.0297, 0.9684, 1.0099, 1.0024, 1.0163, 1.0406, 1.0379, 1.0185,\n",
      "        1.0524, 0.9933, 1.0043, 0.9651, 0.9833, 0.9618, 1.0261, 1.0143, 1.0331,\n",
      "        1.0465, 1.0377, 1.0206, 0.9716, 0.9661, 1.0086, 1.0101, 1.0370, 1.0309,\n",
      "        1.0506, 0.9620, 0.9822, 0.9862, 1.0178, 1.0582, 0.9777, 0.9885, 0.9839,\n",
      "        1.0192, 1.0034, 1.0171, 0.9968, 1.0289, 1.0274, 1.0261, 1.0009, 1.0200,\n",
      "        1.0240, 0.9707, 1.0177, 1.0231, 1.0443, 1.0228, 1.0419, 0.9854, 0.9862,\n",
      "        1.0387, 0.9586, 0.9424, 1.0161, 1.0267, 1.0107, 1.0044, 0.9761, 0.9694,\n",
      "        1.0209, 0.9898, 1.0418, 1.0151, 0.9997, 0.9938, 0.9920, 0.9804, 1.0042,\n",
      "        1.0235, 1.0307, 1.0305, 1.0232, 0.9628, 1.0187], device='cuda:0')\n",
      "batchnorm.bias tensor([-1.9283e-02, -1.3984e-02, -1.2762e-02, -4.2937e-02, -6.4386e-02,\n",
      "        -3.2771e-02, -1.5346e-02, -1.7787e-02, -6.8797e-03, -7.7963e-03,\n",
      "        -1.2363e-02,  3.1580e-02,  1.5253e-02, -1.5276e-02, -4.7483e-03,\n",
      "        -3.4112e-03, -2.0602e-02, -7.3139e-03, -3.9019e-02, -2.2141e-02,\n",
      "        -4.3150e-02, -2.7955e-02, -4.0184e-02,  5.2884e-03, -3.5348e-02,\n",
      "        -8.4813e-03, -8.8507e-03, -1.3176e-02, -3.2639e-02, -3.8290e-02,\n",
      "        -3.1115e-02, -2.9215e-03, -3.5362e-02,  3.9343e-05, -5.6838e-03,\n",
      "        -7.5737e-02, -2.3225e-02, -4.4778e-02, -4.9464e-02, -3.5504e-03,\n",
      "        -9.7436e-03, -4.6882e-03,  7.4130e-03, -5.7194e-02, -3.0795e-02,\n",
      "        -2.7548e-02, -3.4815e-02, -1.3143e-03, -1.4192e-02, -3.5885e-03,\n",
      "        -2.6203e-02, -4.6669e-02, -5.5579e-02, -1.6523e-03, -4.2825e-02,\n",
      "        -2.5236e-02, -5.7271e-02, -4.6873e-02, -4.2792e-02, -6.7766e-03,\n",
      "        -6.7704e-02, -2.3463e-02, -7.4511e-03, -5.9098e-02, -1.1166e-02,\n",
      "        -2.6463e-02, -3.9036e-02, -3.4339e-02, -6.6329e-03, -2.3797e-02,\n",
      "        -1.6155e-02, -1.4825e-02, -6.5600e-02, -1.0185e-01, -1.6877e-02,\n",
      "        -3.7143e-02, -1.1479e-02, -2.4421e-02, -2.9304e-02, -2.8492e-02,\n",
      "        -2.4596e-02, -5.7474e-02, -5.0494e-03, -7.8272e-02, -4.4221e-02,\n",
      "         6.8160e-03, -3.8470e-02, -1.4646e-02, -4.4930e-02, -2.9953e-02,\n",
      "        -2.8544e-02, -6.5737e-03, -3.3140e-02, -5.0396e-02, -1.0619e-01,\n",
      "        -4.5921e-02, -1.6248e-02, -9.2509e-03,  1.4829e-02,  8.7089e-04,\n",
      "        -4.6248e-02, -3.2491e-02, -1.0347e-02, -1.1935e-02, -8.0537e-03,\n",
      "         2.1494e-03,  3.4393e-03, -2.0133e-02, -4.4520e-02, -4.3238e-02,\n",
      "        -2.3009e-02, -2.0891e-02, -1.3938e-02, -3.1119e-02, -6.5495e-02,\n",
      "        -3.0633e-02, -1.6706e-02, -3.5741e-02, -9.2399e-02,  9.8116e-04,\n",
      "        -6.6269e-02, -5.4249e-03, -1.8812e-02, -2.7685e-02,  6.4045e-03,\n",
      "        -1.3233e-02, -7.0107e-03, -1.5517e-02, -2.7064e-02, -6.7943e-02,\n",
      "        -5.5205e-02, -2.1076e-03, -5.8995e-02, -5.8244e-02, -6.5805e-03,\n",
      "        -1.1723e-02, -3.1874e-02, -3.0884e-02, -2.6352e-02, -1.3790e-02,\n",
      "        -6.9072e-03, -5.9095e-03, -5.1334e-02, -2.5992e-02, -3.9165e-02,\n",
      "        -4.3753e-03, -5.1861e-02,  3.3675e-03, -5.3705e-02, -1.6994e-02,\n",
      "        -4.3337e-03, -2.0720e-02, -1.5787e-02, -4.1216e-02, -6.5700e-02,\n",
      "         1.1134e-02, -6.4146e-02, -3.5534e-02, -3.7361e-02, -1.9571e-02,\n",
      "         1.1023e-04, -2.8687e-02, -4.1139e-02, -5.4592e-02, -4.2598e-02,\n",
      "        -2.6962e-02,  8.0412e-03, -2.2631e-02, -8.3424e-03, -8.7857e-03,\n",
      "         2.9212e-03, -2.0526e-03, -2.2093e-02, -1.5824e-02, -4.6184e-03,\n",
      "         1.6732e-02, -2.4617e-03, -3.2712e-02, -6.7965e-03, -1.8735e-02,\n",
      "        -3.1084e-02, -6.4838e-02, -1.3272e-02, -1.3932e-02, -3.6103e-02,\n",
      "        -5.4212e-02, -1.2259e-02, -6.9748e-02, -1.5245e-02, -3.9282e-02,\n",
      "        -3.5391e-02, -4.0551e-02, -2.8473e-02, -7.2670e-03, -4.2241e-02,\n",
      "        -1.6020e-02, -2.3646e-02,  5.4818e-03, -3.4822e-02, -2.8188e-02,\n",
      "        -3.4855e-02,  1.1335e-03, -7.0284e-03, -1.0463e-02, -6.1190e-02,\n",
      "        -1.1120e-02, -3.9513e-02, -3.5398e-02, -4.8352e-02, -5.1072e-03,\n",
      "        -4.2477e-03, -1.4132e-02, -2.7726e-03,  7.2749e-03, -3.3843e-02,\n",
      "         1.5075e-02, -2.7050e-02, -4.3672e-02, -9.4748e-03, -5.7756e-02,\n",
      "        -4.9408e-02, -1.2863e-02, -8.6005e-03, -9.5110e-03, -4.2310e-02,\n",
      "        -4.1205e-02, -4.6509e-02, -5.7217e-02, -2.7575e-02, -2.8391e-02,\n",
      "         4.2869e-04, -1.9165e-02, -3.7026e-02, -1.2767e-02, -1.3991e-03,\n",
      "        -6.6375e-02, -7.2785e-02, -9.8002e-03, -4.1706e-03, -5.0165e-02,\n",
      "        -2.4728e-03, -7.0828e-02, -1.0377e-01, -3.4364e-02, -4.9564e-02,\n",
      "        -1.0679e-02, -1.0680e-02, -1.0063e-02, -2.0172e-02, -1.5822e-02,\n",
      "        -3.1405e-02, -1.2577e-03,  7.3573e-04, -2.9185e-02,  1.1074e-02,\n",
      "        -2.4398e-02, -2.7199e-02, -1.3158e-02, -1.7119e-03, -3.5439e-03,\n",
      "        -1.4612e-02, -2.5176e-02, -4.2032e-02,  8.8238e-03, -1.2489e-02,\n",
      "        -4.1975e-02,  2.0656e-03, -5.6326e-02, -2.1447e-02,  5.4564e-03,\n",
      "        -4.1550e-02,  1.5453e-02, -3.4795e-02,  5.8768e-03, -3.7056e-02,\n",
      "        -5.4604e-02, -6.1608e-02, -2.0313e-02, -3.4564e-02, -2.9125e-02,\n",
      "        -3.1484e-03, -3.8162e-02, -1.5142e-03, -6.6741e-03, -2.5328e-02,\n",
      "        -1.8705e-02, -1.7501e-02, -3.6245e-02, -7.8689e-02, -5.1657e-03,\n",
      "        -3.4922e-02, -5.2670e-03, -9.8528e-03, -3.3324e-03, -2.1539e-02,\n",
      "        -4.0082e-02, -4.1779e-02, -2.0982e-02, -1.5249e-02, -2.1733e-02,\n",
      "         2.1939e-03, -8.8201e-02, -1.2241e-02, -1.8162e-02, -3.5804e-02,\n",
      "        -5.3542e-02, -5.7039e-02, -2.9712e-03, -2.5966e-02, -5.0251e-03,\n",
      "        -2.0275e-02, -1.3137e-02, -6.6764e-03,  1.3117e-02, -1.7466e-02,\n",
      "         2.9964e-03, -3.3897e-03, -6.0180e-03, -5.7405e-02, -4.9386e-02,\n",
      "        -5.0883e-02,  8.6582e-03, -2.1783e-02, -1.3415e-02, -2.2675e-02,\n",
      "         7.4337e-04, -8.5922e-03, -4.2716e-02, -5.2634e-02, -2.9086e-04,\n",
      "        -1.4881e-02, -1.1120e-02, -2.0475e-02, -5.3145e-04, -5.3896e-02,\n",
      "        -8.5531e-03, -1.8670e-02, -1.8315e-02,  2.7310e-03, -4.4484e-02,\n",
      "        -5.2061e-02, -6.6613e-02,  6.3982e-03, -5.6497e-03, -2.8752e-02,\n",
      "        -3.4805e-02, -2.3571e-02, -4.1347e-03, -5.5007e-04, -2.3967e-02,\n",
      "        -2.2918e-02, -1.2101e-03, -5.0536e-02, -1.0359e-02, -8.9866e-03,\n",
      "         9.1402e-03, -2.3545e-02, -7.8095e-03, -2.0181e-02, -2.7419e-02,\n",
      "        -6.3453e-03, -6.3673e-02, -5.9584e-02,  1.5325e-02,  2.9448e-03,\n",
      "        -1.1679e-02, -4.0960e-03, -3.6292e-02, -6.6028e-02, -8.9418e-03,\n",
      "        -2.4855e-02,  1.2127e-02, -1.8527e-02, -2.8772e-02, -3.8110e-02,\n",
      "        -2.0493e-02, -3.2806e-02,  1.7928e-04, -1.2883e-03, -3.1910e-02,\n",
      "         6.9111e-03, -2.3849e-02, -4.7945e-02, -3.5384e-02], device='cuda:0')\n",
      "lstm.weight_ih_l0 tensor([[-0.0205, -0.0422, -0.0289,  ...,  0.0545,  0.0189, -0.0417],\n",
      "        [-0.0109, -0.0334,  0.0130,  ..., -0.0087, -0.0316, -0.0069],\n",
      "        [-0.0059, -0.0482, -0.0585,  ..., -0.0580, -0.0408, -0.0473],\n",
      "        ...,\n",
      "        [-0.0179, -0.0344,  0.0201,  ..., -0.0830, -0.0588, -0.1058],\n",
      "        [-0.0052, -0.0279,  0.0034,  ..., -0.0384, -0.0101,  0.0319],\n",
      "        [ 0.0762,  0.0168, -0.0139,  ...,  0.0112, -0.0325, -0.0482]],\n",
      "       device='cuda:0')\n",
      "lstm.weight_hh_l0 tensor([[ 0.0261,  0.0194, -0.0024,  ...,  0.0297,  0.0118, -0.0632],\n",
      "        [ 0.0583,  0.0111,  0.0137,  ...,  0.0487, -0.0139, -0.0031],\n",
      "        [ 0.0613,  0.0198,  0.0742,  ...,  0.0276, -0.0191,  0.0303],\n",
      "        ...,\n",
      "        [ 0.0346, -0.0087, -0.0227,  ..., -0.0487, -0.0079,  0.0166],\n",
      "        [-0.0140,  0.0084,  0.0226,  ...,  0.0328,  0.0359, -0.0491],\n",
      "        [-0.0664,  0.0041, -0.0016,  ...,  0.0061, -0.0228,  0.0539]],\n",
      "       device='cuda:0')\n",
      "lstm.bias_ih_l0 tensor([-0.0135, -0.0445, -0.0613,  ..., -0.0052, -0.0094, -0.0163],\n",
      "       device='cuda:0')\n",
      "lstm.bias_hh_l0 tensor([-0.0491,  0.0060,  0.0006,  ..., -0.0852, -0.0002,  0.0467],\n",
      "       device='cuda:0')\n",
      "lstm.weight_ih_l1 tensor([[-0.0099, -0.0096,  0.0348,  ..., -0.0209,  0.0390, -0.0331],\n",
      "        [ 0.0130,  0.0007, -0.0185,  ...,  0.0067,  0.0526, -0.0538],\n",
      "        [ 0.0735,  0.0216, -0.0042,  ...,  0.0690, -0.0092, -0.0462],\n",
      "        ...,\n",
      "        [-0.0175,  0.0017, -0.0248,  ..., -0.0014,  0.0135,  0.0053],\n",
      "        [ 0.0475,  0.0340, -0.0263,  ..., -0.0274,  0.0548, -0.0027],\n",
      "        [-0.0060, -0.0207,  0.0306,  ...,  0.0166, -0.0215, -0.0450]],\n",
      "       device='cuda:0')\n",
      "lstm.weight_hh_l1 tensor([[-0.0048,  0.0352, -0.0092,  ...,  0.0430, -0.0674, -0.0306],\n",
      "        [ 0.0190, -0.0327, -0.0361,  ..., -0.0033, -0.0641,  0.0217],\n",
      "        [ 0.0117,  0.0131, -0.0220,  ..., -0.0309,  0.0285,  0.0199],\n",
      "        ...,\n",
      "        [-0.0441,  0.0134, -0.0018,  ..., -0.0130,  0.0103,  0.0311],\n",
      "        [ 0.0059, -0.0226, -0.0287,  ...,  0.0117, -0.0304, -0.0148],\n",
      "        [ 0.0095, -0.0567, -0.0411,  ...,  0.0011,  0.0289, -0.0013]],\n",
      "       device='cuda:0')\n",
      "lstm.bias_ih_l1 tensor([-0.0165, -0.0589, -0.0732,  ...,  0.0107, -0.0130, -0.0398],\n",
      "       device='cuda:0')\n",
      "lstm.bias_hh_l1 tensor([-0.0343, -0.0819, -0.0182,  ...,  0.0260, -0.0487, -0.0325],\n",
      "       device='cuda:0')\n",
      "linear.weight tensor([[ 0.0726,  0.0517,  0.0064,  ...,  0.0428,  0.0309,  0.0274],\n",
      "        [-0.0378,  0.0515, -0.0115,  ...,  0.0958, -0.0591,  0.0168],\n",
      "        [ 0.0809, -0.0457, -0.0057,  ..., -0.0247, -0.0054, -0.0451],\n",
      "        [-0.0698,  0.0325, -0.0475,  ..., -0.0760,  0.0444, -0.0471],\n",
      "        [ 0.0547, -0.0055, -0.0522,  ..., -0.0465, -0.0092,  0.0178]],\n",
      "       device='cuda:0')\n",
      "linear.bias tensor([ 0.0232,  0.0167,  0.0022,  0.0292, -0.0671], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59146b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
