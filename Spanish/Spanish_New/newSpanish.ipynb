{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcff203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "regex = re.compile(r'\\[.+\\]\\n', re.IGNORECASE)\n",
    "file_paths, file_names, emotions = [], [], []\n",
    "emotion_map = {'Neutral': 'neutral', 'Anger': 'angry', 'Happiness': 'happy', 'Sadness': 'sad', 'Fear': 'fear',\n",
    "              'Disgust': 'disgust'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcc58f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 863/863 [00:00<00:00, 729627.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define path to datasets\n",
    "DATA_NATURAL = \"/home/rl3155/MESD_All\"\n",
    "entries = os.listdir(DATA_NATURAL)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(entries))):\n",
    "    entry = entries[i]\n",
    "    path = DATA_NATURAL + \"/\" + entry\n",
    "    if \"wav\" not in path:\n",
    "        continue\n",
    "    emotion = emotion_map[entry.split(\"_\")[0]]\n",
    "    \n",
    "    file_paths.append(path)\n",
    "    file_names.append(entry)\n",
    "    emotions.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08cd075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.DataFrame({'path':file_paths, 'name': file_names, 'emotion': emotions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277cf819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/rl3155/MESD_All/Anger_C_B_delincuencia.wav</td>\n",
       "      <td>Anger_C_B_delincuencia.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/rl3155/MESD_All/Happiness_M_A_hoy.wav</td>\n",
       "      <td>Happiness_M_A_hoy.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/rl3155/MESD_All/Disgust_C_B_irrespetuoso...</td>\n",
       "      <td>Disgust_C_B_irrespetuoso.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/rl3155/MESD_All/Sadness_M_B_hambre.wav</td>\n",
       "      <td>Sadness_M_B_hambre.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/rl3155/MESD_All/Neutral_F_A_izquierda.wav</td>\n",
       "      <td>Neutral_F_A_izquierda.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0   /home/rl3155/MESD_All/Anger_C_B_delincuencia.wav   \n",
       "1        /home/rl3155/MESD_All/Happiness_M_A_hoy.wav   \n",
       "2  /home/rl3155/MESD_All/Disgust_C_B_irrespetuoso...   \n",
       "3       /home/rl3155/MESD_All/Sadness_M_B_hambre.wav   \n",
       "4    /home/rl3155/MESD_All/Neutral_F_A_izquierda.wav   \n",
       "\n",
       "                           name  emotion  \n",
       "0    Anger_C_B_delincuencia.wav    angry  \n",
       "1         Happiness_M_A_hoy.wav    happy  \n",
       "2  Disgust_C_B_irrespetuoso.wav  disgust  \n",
       "3        Sadness_M_B_hambre.wav      sad  \n",
       "4     Neutral_F_A_izquierda.wav  neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4153e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "spaths, semotions = shuffle(file_paths, emotions, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a55670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(spaths, semotions, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371d6085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "0.12.1+cu113\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4675fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchaudio.models.wav2vec2.model.Wav2Vec2Model'>\n"
     ]
    }
   ],
   "source": [
    "bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
    "extractor = bundle.get_model()\n",
    "print(extractor.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a75bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, labels, label_transform):\n",
    "        super(MyDataSet).__init__()\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.label_transform = label_transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        label = self.label_transform[self.labels[idx]]\n",
    "        wave, sr = torchaudio.load(path)\n",
    "        if sr != bundle.sample_rate:\n",
    "            wave = torchaudio.functional.resample(wave, sr, bundle.sample_rate)\n",
    "        with torch.inference_mode():\n",
    "            feature, _ = extractor.extract_features(wave)\n",
    "        feature = [f[0] for f in feature]\n",
    "        audio = torch.stack(feature)\n",
    "        length = audio.size(1)\n",
    "        return audio, length, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141ec40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_indic(data):\n",
    "    audios, lengths, labels = zip(*data)\n",
    "    max_len = max(lengths)\n",
    "    n_ftrs = audios[0].size(2)\n",
    "    n_dims = audios[0].size(0)\n",
    "    features = torch.zeros((len(audios), n_dims, max_len, n_ftrs))\n",
    "    labels = torch.tensor(labels)\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        j, k = audios[i].size(1), audios[i].size(2)\n",
    "        features[i] = torch.cat([audios[i], torch.zeros((n_dims, max_len - j, k))], dim=1)\n",
    "\n",
    "    return features, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0738ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'angry': 1, 'happy': 2, 'sad': 3, 'fear': 4, 'disgust': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['neutral', 'angry', 'happy', 'sad', 'fear', 'disgust']\n",
    "cate_dic = {}\n",
    "for i, cate in enumerate(categories):\n",
    "    cate_dic[cate] = i\n",
    "cate_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aa549a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = MyDataSet(X_train, y_train, cate_dic)\n",
    "trainloader_args = dict(batch_size=16, shuffle=True)\n",
    "train_dataloader = DataLoader(train_dataset, **trainloader_args, \n",
    "                              collate_fn=collate_indic)\n",
    "\n",
    "test_dataset = MyDataSet(X_val, y_val, cate_dic)\n",
    "testloader_args = dict(batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, **testloader_args, \n",
    "                             collate_fn=collate_indic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4848c",
   "metadata": {},
   "source": [
    "## Train with 3CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ef1a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ICASSP3CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, dims = 12, embed_size=128, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=7):\n",
    "        super().__init__()\n",
    "        self.n_layers = num_lstm_layers \n",
    "        self.hidden = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.aggr = nn.Conv1d(in_channels=dims, out_channels=1, kernel_size=1)\n",
    "        \n",
    "        self.embed = nn.Linear(in_features = vocab_size, out_features = embed_size)\n",
    "\n",
    "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm1d(3 * embed_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = 3 * embed_size, \n",
    "                            hidden_size = hidden_size, \n",
    "                            num_layers = num_lstm_layers, \n",
    "                            bidirectional = bidirectional)\n",
    "\n",
    "        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n",
    "                                out_features = label_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        padded_x: (B,T) padded LongTensor\n",
    "        \"\"\"\n",
    "        n, d, b, t = x.size(0), x.size(1), x.size(2), x.size(3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        input = self.aggr(x)\n",
    "        input = torch.reshape(input, (n, b, t))\n",
    "        input = self.embed(input)\n",
    "\n",
    "        batch_size = input.size(0)\n",
    "        input = input.transpose(1,2)    # (B,T,H) -> (B,H,T)\n",
    "\n",
    "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
    "\n",
    "        input = F.relu(self.batchnorm(cnn_output))\n",
    "\n",
    "        input = input.transpose(1,2)\n",
    "\n",
    "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, cn) = self.lstm(pack_tensor)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n",
    "            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n",
    "        else:\n",
    "            h_n = hn[-1]\n",
    "\n",
    "        logits = self.linear(h_n)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7d392",
   "metadata": {},
   "source": [
    "### Model Traning on each layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75762bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████                                                                                                                                                                                                       | 1/50 [01:45<1:25:54, 105.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, train accu:0.1858, train loss:1.87, valid accu:0.2428, valid loss:1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|████████                                                                                                                                                                                                   | 2/50 [03:27<1:22:48, 103.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2, train accu:0.1771, train loss:1.80, valid accu:0.3121, valid loss:1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████████████▏                                                                                                                                                                                              | 3/50 [05:12<1:21:26, 103.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3, train accu:0.2337, train loss:1.67, valid accu:0.2890, valid loss:1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████████████████▏                                                                                                                                                                                          | 4/50 [06:56<1:19:49, 104.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4, train accu:0.3149, train loss:1.55, valid accu:0.3295, valid loss:1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████████████████▎                                                                                                                                                                                      | 5/50 [08:38<1:17:33, 103.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5, train accu:0.2961, train loss:1.48, valid accu:0.2890, valid loss:1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████████████████████████▎                                                                                                                                                                                  | 6/50 [10:21<1:15:48, 103.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6, train accu:0.3483, train loss:1.37, valid accu:0.3006, valid loss:1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████████████████████▍                                                                                                                                                                              | 7/50 [12:05<1:14:13, 103.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7, train accu:0.4383, train loss:1.28, valid accu:0.3006, valid loss:1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████████████████████████▍                                                                                                                                                                          | 8/50 [13:48<1:12:16, 103.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8, train accu:0.4906, train loss:1.18, valid accu:0.3468, valid loss:1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|████████████████████████████████████▌                                                                                                                                                                      | 9/50 [15:30<1:10:13, 102.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9, train accu:0.5515, train loss:1.08, valid accu:0.5376, valid loss:1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████████████████████████████▍                                                                                                                                                                 | 10/50 [17:12<1:08:24, 102.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, train accu:0.6038, train loss:0.95, valid accu:0.5145, valid loss:1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|████████████████████████████████████████████▍                                                                                                                                                             | 11/50 [18:53<1:06:20, 102.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11, train accu:0.5922, train loss:0.95, valid accu:0.5318, valid loss:1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|████████████████████████████████████████████████▍                                                                                                                                                         | 12/50 [20:35<1:04:37, 102.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12, train accu:0.6415, train loss:0.78, valid accu:0.5896, valid loss:0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████████████████████████████████████▌                                                                                                                                                     | 13/50 [22:17<1:02:56, 102.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13, train accu:0.6865, train loss:0.76, valid accu:0.5607, valid loss:1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|████████████████████████████████████████████████████████▌                                                                                                                                                 | 14/50 [24:01<1:01:34, 102.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14, train accu:0.7402, train loss:0.64, valid accu:0.6069, valid loss:1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████████████████████████████████████████████▏                                                                                                                                              | 15/50 [25:43<59:52, 102.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15, train accu:0.7039, train loss:0.77, valid accu:0.5376, valid loss:1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████████████████████████████████████████████▎                                                                                                                                          | 16/50 [27:25<57:57, 102.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16, train accu:0.6952, train loss:0.68, valid accu:0.5954, valid loss:0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|█████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 17/50 [29:07<56:13, 102.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17, train accu:0.7620, train loss:0.55, valid accu:0.6763, valid loss:0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                  | 18/50 [30:48<54:23, 101.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18, train accu:0.7765, train loss:0.51, valid accu:0.6127, valid loss:1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                              | 19/50 [32:30<52:36, 101.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19, train accu:0.7808, train loss:0.54, valid accu:0.6590, valid loss:0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 20/50 [34:12<50:59, 101.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20, train accu:0.8200, train loss:0.48, valid accu:0.7341, valid loss:0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                      | 21/50 [35:54<49:13, 101.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21, train accu:0.8752, train loss:0.38, valid accu:0.7052, valid loss:0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 22/50 [37:35<47:25, 101.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22, train accu:0.8970, train loss:0.32, valid accu:0.7283, valid loss:0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 23/50 [39:18<45:53, 101.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23, train accu:0.8810, train loss:0.34, valid accu:0.6879, valid loss:0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 24/50 [41:00<44:13, 102.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24, train accu:0.8824, train loss:0.33, valid accu:0.7399, valid loss:0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                      | 25/50 [42:44<42:47, 102.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25, train accu:0.9216, train loss:0.26, valid accu:0.7225, valid loss:0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                  | 26/50 [44:29<41:18, 103.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26, train accu:0.9390, train loss:0.23, valid accu:0.7052, valid loss:1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 27/50 [46:14<39:51, 103.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27, train accu:0.9202, train loss:0.31, valid accu:0.6994, valid loss:0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 28/50 [48:00<38:18, 104.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28, train accu:0.8853, train loss:0.34, valid accu:0.6994, valid loss:0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 29/50 [49:46<36:42, 104.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29, train accu:0.9158, train loss:0.24, valid accu:0.6243, valid loss:1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                 | 30/50 [51:31<34:57, 104.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30, train accu:0.9289, train loss:0.25, valid accu:0.6647, valid loss:1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                             | 31/50 [53:15<33:07, 104.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31, train accu:0.9448, train loss:0.19, valid accu:0.6647, valid loss:1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 32/50 [54:59<31:20, 104.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32, train accu:0.9594, train loss:0.15, valid accu:0.6994, valid loss:1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                     | 33/50 [56:41<29:25, 103.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33, train accu:0.9724, train loss:0.20, valid accu:0.6763, valid loss:1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 34/50 [58:26<27:46, 104.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34, train accu:0.9521, train loss:0.16, valid accu:0.6705, valid loss:0.98\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "\n",
    "model = ICASSP3CNN(768)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "epochs = 50\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    model.train()\n",
    "    for batch, (x, length, y) in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x, length)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.cpu().item()\n",
    "\n",
    "        #model outputs\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "        batch_cnt += 1\n",
    "    \n",
    "    train_loss = train_loss/batch_cnt\n",
    "    train_accuracy = acc_cnt/(acc_cnt+err_cnt)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    valid_loss = 0\n",
    "    acc_cnt = 0\n",
    "    err_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    model.eval()\n",
    "\n",
    "    for x, lengths, y in test_dataloader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x, lengths)\n",
    "        loss = criterion(logits, y)\n",
    "        valid_loss += loss.cpu().item()\n",
    "\n",
    "        out_val, out_indices = torch.max(logits, dim=1)\n",
    "        tar_indices = y\n",
    "\n",
    "        for i in range(len(out_indices)):\n",
    "            if out_indices[i] == tar_indices[i]:\n",
    "                acc_cnt += 1\n",
    "            else:\n",
    "                err_cnt += 1\n",
    "        batch_cnt += 1\n",
    "    \n",
    "    valid_loss = valid_loss/batch_cnt\n",
    "    valid_accuracy = acc_cnt/(acc_cnt+err_cnt)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f\"epoch:{epoch+1}, train accu:{train_accuracy:.4f},\", \n",
    "          f\"train loss:{train_loss:.2f}, valid accu:{valid_accuracy:.4f},\", \n",
    "          f\"valid loss:{valid_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/rl3155/models/wav2vecbase_new.pth'\n",
    "\n",
    "torch.save({'epoch':epochs,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict()},\n",
    "            model_path)\n",
    "\n",
    "metadata = pd.DataFrame({'epoch':range(epochs), 'train loss':train_losses, \n",
    "                         'valid loss':valid_losses, 'train accu':train_accuracies, \n",
    "                         'valid_accu':valid_accuracies})\n",
    "metadata.to_csv('/home/rl3155/results/acc_loss/wav2vecbase_new.csv ', \n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epochs), train_losses, label='train')\n",
    "plt.plot(range(epochs), valid_losses, label='valid')\n",
    "plt.legend()\n",
    "plt.title('training and validation loss')\n",
    "plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), train_accuracies, label='train')\n",
    "plt.plot(range(epochs), valid_accuracies, label='valid')\n",
    "plt.legend()\n",
    "plt.title('training and validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for inputs, lengths, labels in test_dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = model(inputs, lengths) # Feed Network\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ecd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "classes = list(set([v[1] for k,v in waveforms_results_dict.items()]))\n",
    "df_cm = pd.DataFrame(cf, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Spanish Wav2VecBase Confusion Matrix')\n",
    "plt.savefig('/home/rl3155/results/confusion_matrix/wav2vecbase_new.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74a066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
